export default {
  "tickets": [
    {
      "Short Desc.": "Stuck Insert statement",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8590",
      "Ticket Number": "#8590",
      "Title": "Re: EOG PROD - INSERT statements hanging on ie_dba.ie_key_metric_entity_wide_out on 2019-05-20",
      "EOG cluster": "ktymsql30",
      "Host": "",
      "Solution": "Issue solved itself / Webexen beszéltek",
      "Commands": "Process list for LEAF # memsql-ops memsql-list | grep LEAF | awk '{print $6,$7}' | while read host port; do memsql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"select * from information_schema.processlist;\" > /tmp/leaf_${host}_${port}_processlist.txt;done\nProcess list for AGGREGATOR # memsql-ops memsql-list | grep -E 'MASTER|AGGREGATOR' | awk '{print $6,$7}' | while read host port; do memsql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"select * from information_schema.processlist;\" > /tmp/${host}_${port}_agg_processlist.txt;done",
      "RCA": "Van a ticketben egy elég hosszú rész \"Next Step\".el kezdődik. Végül minden leaf minden ment, 1 tábla volt ahol az insert beragadt. kellet csinálni egy backtrace-t [memsql> _BT;] és egy cluster restartot. Utána is ugyan úgy beragadtak a inzertek, a reportok alapján: [Waiting for metadata lock...]-al.",
      "Comments": "",
      "EOG_Ticket#": ""
    },
    {
      "Short Desc.": "DB Replication failed",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8503",
      "Ticket Number": "#8503",
      "Title": "Eog Prd : Replication error. need to resolve",
      "EOG cluster": "ktymsqlstg31",
      "Host": "",
      "Solution": "Replicating database with new name (https://docs.memsql.com/sql-reference/v6.8/replicate-database/)",
      "Commands": "REPLICATE DATABASE db_name FROM master_user[:'master_password']@master_host[:master_port][/master_db_name]",
      "RCA": "Elfailelt, nem tudta rplicálni a database-t Failed to synchronize database. Invalid database state: unrecoverable. STG és a Prodnak más volt a verziószáma, és ugyan annak kéne lennie. Ezért kellet használni a [mysqldump] toolt pár tábla átvitelére. Utána restorolni szerette volna, de nem lehet más verziószámút backupolni STG-n átvinni PROD-ra és ott restorolni (https://docs.memsql.com/sql-reference/v6.8/restore/)",
      "Comments": "",
      "EOG_Ticket#": "",
      
    },
    {
      "Short Desc.": "Long compile times",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8420",
      "Ticket Number": "#8420",
      "Title": "EOG - Long compile times observed 2019-06-14",
      "EOG cluster": "ktymsql30",
      "Host": "",
      "Solution": "interpret_mode is set to 'INTERPRET_FIRST' megoldotta, viszont az csak 6.8-ban van",
      "Commands": "memsql> SHOW CLUSTER STATUS; dmesg -T (hardware failures)",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Lock wait timeout exceeded",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8429",
      "Ticket Number": "#8429",
      "Title": "Leaf Error (ktymsql17:3307): Lock wait timeout exceeded; try restarting transaction",
      "EOG cluster": "ktymsql30",
      "Host": "",
      "Solution": "Kill the locking connection",
      "Commands": "memsql-ops report, KILL CONNECTION \"\"insert transaction id;",
      "RCA": "We need the reports from the cluster. Looking over transactions, look for LOCKS_HELD. Once found find the aggregator that sent the transaction. Kill them both. First the leaf then the aggregator To avoid this happening next time make sure all the changes are commited",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Host Name or IP does NOT show",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8483",
      "Ticket Number": "#8482 #8483",
      "Title": "Seems the Host Name or IP does NOT shows in process list view .",
      "EOG cluster": "",
      "Host": "",
      "Solution": "",
      "Commands": "memsql-ops memsql-update-config --key skip_name_resolve --value \"OFF",
      "RCA": "Execute command on the cluster, restart it.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "IS GEOMETRY Data type supported",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8344",
      "Ticket Number": "#8344",
      "Title": "IS GEOMETRY Data type supported",
      "EOG cluster": "",
      "Host": "",
      "Solution": "No",
      "Commands": "",
      "RCA": "POINT LINESTRING POLYGON are supported. MULTIPOLYGON, GEOMETRY, CURVE are not. Feature request has been opened.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Not enough memory available to complete the current request.",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8311",
      "Ticket Number": "#8311",
      "Title": "Eog Prod - 2019-05-31 - Leaf Error (ktymsql17:3308): Leaf Error (ktymsql16:3308): Not enough memory available to complete the current request.",
      "EOG cluster": "ktymsql30",
      "Host": "",
      "Solution": "vm.max_map_count configuration",
      "Commands": "select * from MV_NODES;",
      "RCA": "Check for data skew, collect logs from ftp, collect output of select * from information_schema.MV_NODES Check for any recent changes. Try reducing concurrency. Reproduce error with single query.  I noticed vm.max_map_count is misconfigured on host 10.4.55.30. It is set to 100,000,000. It should be set to 1,000,000,000.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Not enough memory available to complete the current request.",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8168",
      "Ticket Number": "#8168",
      "Title": "EOG Prod - insert statement failing with memory error",
      "EOG cluster": "ktymsqlstg",
      "Host": "",
      "Solution": "A megoldást az volt, hogy a vm.max_map_count = 100000000 ról át kellett rakni vm.max_map_count = 1000000000 -re a LEAFeken(ami a recommended). Utána már lefutott hiba nélkül",
      "Commands": "cat /proc/meminfo\nsudo sysctl -a\nPROFILE select_query;\nSHOW PROFILE;",
      "RCA": "Nem futott le egy querry leaf error miatt. A megoldást az volt, hogy a vm.max_map_count = 100000000 ról át kellett rakni vm.max_map_count = 1000000000 -re a LEAFeken(ami a recommended). Utána már lefutott hiba nélkül",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Queuing querries",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8127",
      "Ticket Number": "#8127",
      "Title": "EOG - ktymsqlstg - Workload Management queueing queries on 2019-05-06",
      "EOG cluster": "ktymsqlstg",
      "Host": "",
      "Solution": "SET GLOBAL workload_management_max_connections_per_leaf = 20000 (default value 10000)\nA querryben a datatype mismatch kijavítása -> EOG részről",
      "Commands": "SET GLOBAL workload_management_max_connections_per_leaf = 20000 (default value 10000)\nSHOW WORKLOAD MANAGEMENT STATUS",
      "RCA": "Queued querry, mert a workload management ON.  (https://docs.memsql.com/concepts/v6.7/workload-management/)\nConnections Threshold to Queue Globally is 1666. At the time Running Connections Per Leaf (from local queue) is 493. Our theory is the next queued query was estimated to use approximately 1,100 intra-cluster connections which would have breached Connections Threshold to Queue Globally therefore the query was prevented from running by placing it into a queued state to wait until the currently running query finishes execution (note: Running Queries (from local queue) is 1 in output of show_workload_management_status).\nAz első querry valszeg datatype mismatch miatt futott olyan sokáig és foglalta a helyet a többi querry elől.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Nodes Offline / Not running",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8119",
      "Ticket Number": "#8119",
      "Title": "Node start hanging",
      "EOG cluster": "ktymsql30",
      "Host": "ktymsql27",
      "Solution": "Újraindítás megoldotta",
      "Commands": "./service start --user=memsql (Navigate to the main install directory of each node on ktymsql27 and run the service script located there.)",
      "RCA": "Master aggregátor lelőte a node-okat connection issue miatt.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Nodes Offline / Not running",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8085",
      "Ticket Number": "#8085",
      "Title": "Memsql Stopped on two nodes",
      "EOG cluster": "ktymsqlb",
      "Host": "ktymsqlb03, ktymsqlb04",
      "Solution": "memsql-ops cluster-manual-control --disable (should be disabled) ez át lett állítve --enable ről --disable re",
      "Commands": "dmesg -T\nmemsql-ops cluster-manual-control --disable (should be disabled)",
      "RCA": "These nodes were not running which was likely due to them being OOM killed by the Linux OOM Killer and not",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Studio crashes (Update ticket)",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8054",
      "Ticket Number": "#8054",
      "Title": "EOG Studio's application state",
      "EOG cluster": "n/a",
      "Host": "",
      "Solution": "n/a",
      "Commands": "Javascipt in chrome [JSON.stringify(store.getState())]",
      "RCA": "n/a",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Slowness in ktymsql30 cluster",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8045",
      "Ticket Number": "#8045",
      "Title": "Slowness in ktymsql30 cluster..",
      "EOG cluster": "ktymsql30",
      "Host": "",
      "Solution": "check if transaction reamining open are intended if not make changes to the querys",
      "Commands": "",
      "RCA": "We need the reports from the cluster. Transactions were open, changes never commited.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "how to change max_connection_threads",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8041",
      "Ticket Number": "#8041",
      "Title": "how to change max_connection_threads",
      "EOG cluster": "",
      "Host": "",
      "Solution": "",
      "Commands": "memsql-ops memsql-list -q -r aggregator master | xargs -L 1 memsql-ops memsql-update-config --key max_connection_threads --value VALUE --set-global",
      "RCA": "User wanted to change max connection threads and asking for assistence. Memsql recomends not changing the default values as incresing it will lead to more resource usage that might suffocate the cluster. Changes can be made in small ammounts under close monitoring.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "user privileges changed",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8031",
      "Ticket Number": "#8031",
      "Title": "EOG Prod : user privileges changed, need help in finding",
      "EOG cluster": "",
      "Host": "",
      "Solution": "The only current way to track user permission changes is to use the admin_only level of our audit_logging functionality to track GRANT statements, which is the way that a user's password would be changed.",
      "Commands": "User privileges change caused access denied errors on master aggregator. Child aggregators remained unaffected as permission handling is different on every node",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Memory usage on Nodes ( Column 'MV_NODES.IP_ADDR' from project list is used outside an aggregate function and does not appear in the GROUP BY clause)",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8024",
      "Ticket Number": "#8024",
      "Title": "Memory usage on Nodes ( Column 'MV_NODES.IP_ADDR' from project list is used outside an aggregate function and does not appear in the GROUP BY clause)",
      "EOG cluster": "",
      "Host": "",
      "Solution": "ticked closed without action",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Partition ie_dba:12 has no master instance",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8014",
      "Ticket Number": "#8014",
      "Title": "Partition ie_dba:12 has no master instance, , 'Partition odm_dba:12 has no master instance.",
      "EOG cluster": "ktymsql30",
      "Host": "ktymsql27",
      "Solution": "",
      "Commands": "memsql -e \"SHOW CLUSTER STATUS\" > show_cluster_stauts.txt, memsql -e \"SHOW LEAVES\" > show_leaves.txt KILL CONNECTION \"\"insert transaction id; SHOW REPLICATION STATUS",
      "RCA": "Issue is most likely caused by nodes beeing offline. After this the ticket turned into a slowness analysis, which found that the workload was too big. Also some processes stucked running and had to be killed manually. They restarted the cluster instead. Replication was not working however tha users did not wait for the full recovery. Replication worked again after that. User reported querys being slow. Best practises were applied to the nodes to increase speed. vm.max_map_count\n\nOn all the hosts, vm.max_map_count is set 10x smaller than we recommend. It is currently set to 100000000 and we recommend 1000000000 per our best practices.\n\nhttps://docs.memsql.com/installation/v6.7/system-requirements/#configure-linux-vm-settings\n\nNUMA on ktymsql27\n\nNUMA nodes not bound 1:1 on host ktymsql27. NUMA nodes 0,1,2,3 bound to leaf node ktymsql27:3309, leaf node ktymsql27:3307, leaf node ktymsql27:3306, leaf node ktymsql27:3308\n\nWe suggest 1 socket to 1 node\n\nhttps://docs.memsql.com/installation/v6.7/configure-numa/\n\nDisk usage on a backup dir\n\nThe /memsql_backup on ktymsql11 is 91% full\n\nOnly nodes on ktymsql27 are using our recommended value for columnstore_segment_rows of 1,024,000. All other nodes are using the old value of 102,400. If you decide to change this, please do so after testing on Dev first.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Error Code: 1146. Leaf Error (): Table '' doesn't exist",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8620",
      "Ticket Number": "#8620",
      "Title": "EOG - Error Code: 1146. Leaf Error (ktymsqla09:3306): Table 'ioptimize_dba_123.PL_NODE_META_CYG' doesn't exist",
      "EOG cluster": "ktymsqla01",
      "Host": "",
      "Solution": "recreate table with its original script from leaf or slave",
      "Commands": "Error Code: 1146. Leaf Error (ktymsqla09:3306): Table 'ioptimize_dba_123.PL_NODE_META_CYG' doesn't exist\n connect to cluster in dbeaver and show partitions or show databases extended;\n then\n SELECT a.ordinal,a.host,a.port,a.role,b.host,b.role,b.port\n FROM information_schema.distributed_partitions a\n  JOIN information_schema.distributed_partitions b\n  ON a.database_name=b.database_name and a.ordinal=b.ordinal and a.role='Master' and b.role='Slave'\n WHERE a.database_name='ioptimize_dba' and a.ordinal=123\n GROUP BY 1,2,3,4,5,6,7\n ORDER BY a.ordinal ASC;\n --here you can see the ordinal and its Master, as it is in title/subject;\n ssh ktymsqla09;\n check for table DDL->\n show create table PL_NODE_META_CYG;\n run of DDL on the leaf! needed, earlier it should have been on the master \n this caused dataloss so reload needed",
      "RCA": "partitions check from cluster's partition db\n check leaf dbs and tables\n caused by probably altering happened during leafdown with high partitions",
      "Comments": "advise on recreate and repartition based on 8:1 or 4:1 core:partition \n suggested:\n 1. Create database with proper partitions count\n 2. Load data into the new database\n 3. Drop the old database\n 4. Rename the new database (with better partition count)",
      "EOG_Ticket#": 120471,
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Orphane databases were not dropped during upgrade",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8661",
      "Ticket Number": "#8661",
      "Title": "EOG Prod - Upgrade stuck, orphan databases appear implicated",
      "EOG cluster": "ktymsqlitc11",
      "Host": "",
      "Solution": "workload management turn off",
      "Commands": "in dbeaver on cluster:\n show variables extended like '%workload%';\n show variables extended like '%thread%';\n workload_management_max_threads_per_leaf set higher to 8192\n steps taken by MemSQL Vendor:\n EXPLAIN CLEAR ORPHAN DATABASES;\n CLEAR ORPHAN DATABASES;\n plus set memory sizes:\n memsql-ops memsql-update-config --key maximum_memory --value 285747 --set-global 230977E\n memsql-ops memsql-update-config --key maximum_memory --value 285747 --set-global F45F7D4\n \n memsql-ops memsql-update-config --key maximum_memory --value 252728 --set-global 196E4CB\n memsql-ops memsql-update-config --key maximum_memory --value 252728 --set-global 86FBC85\n memsql-ops memsql-update-config --key maximum_memory --value 252728 --set-global 1817C38\n memsql-ops memsql-update-config --key maximum_memory --value 252728 --set-global 968A855\n memsql-ops memsql-restart 230977E...",
      "RCA": "dbs were not dropped, appeared from log, they were orphaned,",
      "Comments": "",
      "EOG_Ticket#": 121371,
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Supported file system",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8602",
      "Ticket Number": "#8602",
      "Title": "MemSQL Installation Best Practises",
      "EOG cluster": "n/a",
      "Host": "",
      "Solution": "n/a",
      "Commands": "n/a",
      "RCA": "n/a",
      "Comments": "xfs or ext4 is the recommened partition? Answer:both \"In general, ext4 and xfs are both supported filesystems\",but \"ensure that the xfs sector size matches the sector size of your RAID controller",
      "EOG_Ticket#": "outside from eog",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "No host-based grants",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8483",
      "Ticket Number": "#8483",
      "Title": "Seems the Host Name or IP does NOT shows in process list view .",
      "EOG cluster": "houmsqlgng85",
      "Host": "",
      "Solution": "set skip_name_resolve to OFF on Master Aggregator and Child",
      "Commands": "reportcheck:\n sbroomhead:cluster-report-20190620T222457 admin$ find . -name \"memsql_info.json\" | xargs grep -B1 skip_name_resolve | grep Value\n ./agent-A3da472-houmsqlgng86-9000-follower-leaf/memsql-D2EE201-leaf-3307/memsql_info.json- \"Value\": \"AUTO\",\n set to off\n memsql-ops memsql-update-config --key skip_name_resolve --value \"OFF\"\n output of its command:\n \"\n  Index ID Agent Id Process State Cluster State Role Host Port Version\n  1 20AE121 Af5f55a RUNNING CONNECTED MASTER 10.0.0.192 3306 6.8.1\n  2 C69E810 Af5f55a RUNNING CONNECTED LEAF 10.0.0.192 3307 6.8.1\n  3 All MemSQL nodes\n Select an option: 1\n Updating MemSQL config\n 2019-06-21 06:45:32: J423fb0 [INFO] Changing config for MemSQL node 20AE121F5E92F71A6BBB0777A48EF897F9164AC0 on Agent Af5f55a78547b493f9aba6faf6fa155c3 with values {\"skip_name_resolve\":\"OFF\"}\n 2019-06-21 06:45:32: J423fb0 [INFO] Successfully updated config for MemSQL node 20AE121F5E92F71A6BBB0777A48EF897F9164AC0\n MemSQL node 20AE121F5E92F71A6BBB0777A48EF897F9164AC0 is running. You will need to restart it before your config changes take effect. <----------\n \"\n master-agg-and-leaf-ip-10-0-0-192 /home/admin $ memsql-ops memsql-update-config --key skip_name_resolve --value \"OFF\"\n then restart nodes need",
      "RCA": "there is no host-based grants on houmsqlgng85,",
      "Comments": "SELECT ID, USER, HOST, DB, STATE FROM information_schema.processlist\" result listed HOST only partially,other clustered retrieved full info\n  8482ticket was merged into this\n Ticket priorities\n Urgent - Critical production outage.\n High - Major business impact.\n Normal - Minimal business impact, development environment outage.\n Low - General product questions and feature requests.\n select * from information_schema.user_privileges->this shows there are no specific host/ip based grants on that cluster\n | GRANTEE | TABLE_CATALOG | PRIVILEGE_TYPE | IS_GRANTABLE |\n +----------------------+---------------+-------------------------+--------------+\n | 'completion_app'@'%' | def | USAGE | NO",
      "EOG_Ticket#": "outside from eog",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Queries are on QUEUE status ( after migration)",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8668",
      "Ticket Number": "#8668",
      "Title": "Eog Prod: Prod migration .. many queries are on QUEUE status",
      "EOG cluster": "ktymsqlitc11",
      "Host": "Workload management needs to be turned off\n or max threads can be increase\n but simple wait is needed - 20-25 seconds took-, becasue on new cluster queries should be compiled to byte code that takes much time for each fresh/new query\n threads can set to allocate much threads to queries but compile needs much mor time for first",
      "Solution": "check status: show variables extended like '%workload%';\n memsql-ops memsql-update-config --key workload_management --value off --set-global\n see if workload_management is set or not;\n ref_repl_mgmt_threads and repl_mgmt_threads adjust with\n memsql-ops memsql-update-config --key repl_mgmt_threads --value [VALUE] --all --set-global\n memsql-ops memsql-update-config --key ref_repl_mgmt_threads --value [VALUE] --all --set-global\n check locks on clusters\n memsql-ops memsql-list | grep LEAF | awk '{print $6,$7}' | while read host port; do memsql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"select * from information_schema.processlist;\" > /tmp/leaf_${host}_${port}_processlist.txt;done\n memsql-ops memsql-list | grep -E 'MASTER|AGGREGATOR' | awk '{print $6,$7}' | while read host port; do memsql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"select * from information_schema.processlist;\" > /tmp/${host}_${port}_agg_processlist.txt;done\n then\n cd /tmp; find . -name \"*processlist.txt\" -exec grep -HrniE \"wait|lock\" {} \\;",
      "Commands": "user info helped because cluster report did not contain queued qs",
      "RCA": "max_connection_threads is 8192 on memsql techno\n https://docs.memsql.com/troubleshooting/latest/capacity-limit-error/#warn-the-ready-queue-has-not-decreased-currently-num-elements-num-pops-for-num-seconds-this-workload-needs-more-threads\n https://docs.memsql.com/concepts/v6.8/code-generation/\n definitions\n repl_mgmt_threads\n \"The number of threads pooled for replication management of partition databases.\"\n ref_repl_mgmt_threads\n \"The number of threads pooled for replication management of reference databases.",
      "Comments": "n/a",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Statements hanging on",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8242",
      "Ticket Number": "#8242",
      "Title": "EOG PROD - INSERT statements hanging on ie_dba.ie_key_metric_entity_wide_out on 2019-05-20",
      "EOG cluster": "ktymsql30",
      "Host": "restart cluster;\n at next similar occurence core-dump file needs to be generated",
      "Solution": "memsql> KILL CONNECTION 179938; \n before restart cluster `memsql> _BT; for backtrace on leaf not on master, leaf has the important details\n free -h;\n EXPLAIN CLEAR ORPHAN DATABASES;\n processlists from all leaves\n memsql-ops memsql-list | grep LEAF | awk '{print $6,$7}' | while read host port; do memsql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"select * from information_schema.processlist;\" > /tmp/leaf_${host}_${port}_processlist.txt;done\n processlists from all aggregators \n memsql-ops memsql-list | grep -E 'MASTER|AGGREGATOR' | awk '{print $6,$7}' | while read host port; do memsql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"select * from information_schema.processlist;\" > /tmp/${host}_${port}_agg_processlist.txt;done\n These will give us the process list for all the aggregators and leaves.\n memsql-ops report --include-backtrace;\n slow inserts check: MacBook-Pro Wed May 29 08:34:03 proclist$ find . -name \\*processlist.txt | xargs grep -i insert | awk {'print $6'} | sort -nr | head\n \n during same hanging:\n memsql-ops report\n cluster-report-20190529T011108$ find . -name stack_dump.txt | xargs grep -B1 ReleaseAllCodeGenLocks | grep Acquire\n if there is output take a core dump\n SSH into the host of the affected leaf node\n Use ps aux | grep memsqld to locate the pid of the affected memsql node. A single memsql node may have multiple pids. Choose the lowest pid of the multiple pids for a single memsql node.\n Run sudo prlimit --core=unlimited --pid=memsqld_pid_here. Note: memsqld_pid_here represents the actual pid of the affected memsql node.\n To force the affected memsql node to crash and create a core dump run: sudo kill -ABRT memsqld_pid_here. By default the core dump will be created in the data directory of the memsql node that was cored.",
      "Commands": "sleep transaction were detected from one leaf , killed that transaction not solved first time, also other long running queries are noticed from report;\n mentioned table was a rowstore so memory usage was also checked;\n cluster had orphane dbs;\n system configuration was checked and found swap wekanesses, advise was sent;\n slowly running inserts were searched",
      "RCA": "https://docs.memsql.com/installation/v6.7/system-requirements/#configure-linux-vm-settings \"Some of the difficulty we had in troubleshooting this issue is that both ktymsql27 and ktymsql23 failed to generate cluster reports. When Ops cannot generate a cluster report it will write a file report-failure.log in that nodes directory.\" vm.max_map_count not being in line with our best practices->With this value set too low, it risks OOM exceptions",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "High Memory",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8226",
      "Ticket Number": "#8226",
      "Title": "Eog Prd: memory on one leaf node (out of 60 leafs) is always high",
      "EOG cluster": "ktymsql30",
      "Host": "there was no solution",
      "Solution": "SELECT\n  DATABASE_NAME,\n  TABLE_NAME,\n  FLOOR(AVG(ROWS)) AS avg_rows,\n  ROUND(STDDEV(ROWS)/AVG(ROWS),3) * 100 AS row_skew,\n  FLOOR(AVG(MEMORY_USE)) AS avg_memory,\n  ROUND(STDDEV(MEMORY_USE)/AVG(MEMORY_USE),3) * 100 AS memory_skew\n FROM INFORMATION_SCHEMA.TABLE_STATISTICS\n GROUP BY 1, 2\n HAVING SUM(ROWS) > 10000\n ORDER BY row_skew DESC;\n memsql -h0 -uroot -pPASSWORD -e 'show leaves' | awk 'NR>1 {print $1,$2}' | while read host port; do echo ${host} ${port}; memsql -uroot -h${host} -pPASSWORD -P${port} -e \"show status extended;\" | grep -i \"alloc_table_memory\" ;done\n memsql -h0 -uroot -pPASSWORD -e 'show leaves' | awk 'NR>1 {print $1,$2}' | while read host port; do echo ${host} ${port}; memsql -uroot -h${host} -pPASSWORD -P${port} -e \"show status extended;\" ;done\n EXPLAIN CLEAR ORPHAN DATABASES;\n memsql -h HOST -P PORT -u USER -pPASSWORD -e \"SHOW CLUSTER STATUS\" > cluster_status.sql\n To test a better shard key:\n SELECT With(leaf_pushdown=true) \n SUM(c) rows, \n partition_id() partition_id\n FROM ( \n SELECT count(*) c \n FROM <table name> \n GROUP BY <potential shard key>) reshuffle \n GROUP BY partition_id();\n table reshard:\n CREATE TABLE <table_with_new_shard_key_name> (<insert shard key and other keys>) AS INSERT SELECT * FROM <original_table_name>;\n After the new table is created, drop the original table, and rename the new one with the original name.\n \n DROP TABLE original_table_name;\n ALTER TABLE <table_with_new_shard_key_name> RENAME AS original_table_name;\n check partitions to be dropped safe:\n memsql -h HOST -P PORT -u USER -pPASSWORD -e \"SHOW CLUSTER STATUS\" > cluster_status.sql",
      "Commands": "check skewing table statistics\n memory allocation defined , one leaf detected with twice uage\n orphane db check\n large rowstore tables detected with 35-70% skew, should be less than 10%",
      "RCA": "https://docs.memsql.com/tutorials/v6.8/optimizing-table-data-structures/#choosing-a-shard-key suggested to reshard tables",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Cluster build with upgrade",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8220",
      "Ticket Number": "#8220",
      "Title": "Eog Prod : Moving Prod database to new cluster with memsql upgrade",
      "EOG cluster": "",
      "Host": "cluster copy was decided",
      "Solution": "./backup.sh -o p.sql -h node1_d -u root -pwelcome -o output\n Using a password on the command line interface can be insecure.\n memsql-client: [Warning] Using a password on the command line interface can be insecure.\n memsql-client: [Warning] Using a password on the command line interface can be insecure.\n [ec2-user@ip-192-168-1-89 tools]$ cat output\n GRANT USAGE ON *.* TO 'kath'@'localhost' IDENTIFIED BY PASSWORD '*DF216F57F1F2066124E1AA5491D995C3CB57E4C2';\n GRANT ALL PRIVILEGES ON `test`.* TO 'kath'@'localhost';\n GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY PASSWORD '*DF216F57F1F2066124E1AA5491D995C3CB57E4C2' WITH GRANT OPTION;\n GRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' IDENTIFIED BY PASSWORD '*DF216F57F1F2066124E1AA5491D995C3CB57E4C2' WITH GRANT OPTION;\n on new cluster two other set:\n memsql-ops memsql-update-config --key workload_management --value off --set-global\n memsql-ops memsql-update-config --key default_distributed_ddl_timeout --value 180000 --set-global",
      "Commands": "copy replication is also available to move to new cluster\n backup old and restore to new cluster is also option",
      "RCA": "provided user backup sh\n \"#!/bin/bash\n #./user_backup.sh -o <outputfile with sql> -h memsql_host -u user -p password -o /path/to/dsqlfile\n \n #defaults\n outfile=\"grants-$(date +%F_%H_%M).sql\"\n host=\"127.0.01\"\n user=\"root\"\n port=\"3306\"\n \n while getopts \":o:h:u:p:P:\" opt; do\n  case $opt in\n  o) outfile=$OPTARG\n  ;;\n  h) host=$OPTARG\n  ;;\n  u) user=$OPTARG\n  ;;\n  p) pass=$OPTARG\n  ;;\n  P) port=$OPTARG\n  ;;\n  esac\n done\n \n echo \"Backing up grants from $host to the file $outfile\"\n \n \n if [ -z \"$pass\" ]; then \n  mysql_command=\"mysql -h$host -u$user -P$port \"\n else \n  mysql_command=\"mysql -h$host -u$user -P$port -p$pass\"\n fi\n \n echo \"Connection string is: $mysql_command\"\n cmd=\"for i in \\`$mysql_command -e 'select distinct grantee from information_schema.user_privileges;' | awk {'print \\$1'}| grep -v 'grantee'\\`; do $mysql_command -e \"'\"'\"show grants for \\$i\"'\"'\" >> $outfile; done\"\n \n eval $cmd\n sed -i '/Grants for.*/d' \"$outfile\"\n sed -i 's/$/;/' \"$outfile\"\"\n All parameter changes except for sync variables will be saved in memsql.cnf files.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Procedure error",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8163",
      "Ticket Number": "#8163",
      "Title": "EOG STG - procedure not working if num of lines exceed 108",
      "EOG cluster": "ktymsqlstg31",
      "Host": "internal_llvm_detect_cpu_features needed to set off",
      "Solution": "memsql-ops memsql-update-config --key internal_llvm_detect_cpu_features --value off --all --set-global",
      "Commands": "sql procedure's logic and purpose analysed for mentioned \"problematic\" variable\n internal iteration variable does not count and resulted in other figure",
      "RCA": "additional info @#7235\n upgrade to 6.7.11 on 2019-02-05 which contains the fix for the problem\n https://docs.memsql.com/operational-manual/v6.7/upgrading-to-67/",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "changing data_conversion_compatibility_level does not work",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7975",
      "Ticket Number": "#7975",
      "Title": "EOG Prd - changing data_conversion_compatibility_level",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "SET GLOBAL data_conversion_compatibility_level = '6.5'",
      "Commands": "SET GLOBAL data_conversion_compatibility_level = '6.5'",
      "RCA": "Nem tudta lefuttatni, rossz volt a parancs, az adott paranccsal már lefutott",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Querry failing on LEAVES",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7151",
      "Ticket Number": "#7151",
      "Title": "EOG - ktymsql prod - query failing, returns can't open file",
      "EOG cluster": "ktymsql",
      "Host": "ktymsql18 / ktymsql27 leaves",
      "Solution": "Workaround to this error was to try dropping the table and reloading it.\nPlease SSH into the ktymsql27 host and create a database connection directly into the leaf on 3307 [memsql -h ktymsql27 -P 3307]\nThen use the command [EXPLAIN _REPAIR_TABLE [table name]] for each table in the ie_dba_62\n_REPAIR_TABLE [Table_name];\nwe got below message for most of the tables. \nFeature '_REPAIR_TABLE on a non-columnstore table' is not supported by MemSQL\nMemSQL 6.7.8 is available for download now and contains the fix for DB-35358. MemSQL 6.7.8 fixes an issue related to the tracking of missing blobs at end of recovery which was encountered in this case (7151).",
      "Commands": "EXPLAIN _REPAIR_TABLE [table name]",
      "RCA": "Querry nem futott le.\nmemsql> select TABLE_NAME from information_schema.columnar_segments where file = 'columns/ie_dba_62/6/9483886/866650293'; \nEmpty set (13.94 sec) üres az oszlop.\n_REPAIR_TALBE elvileg megoldotta bár non-columnstore tábláknál ez nem működött. De az új verziószámban már javították ezt a bugot elvileg",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Long running querry",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7928",
      "Ticket Number": "#7928",
      "Title": "EOG - count(1) query against information_schema.MV_ACTIVITIES with 3505 rows taking approx. 76 seconds",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "performance improvements from MemSQL side",
      "Commands": "profile select count(1) from information_schema.MV_ACTIVITIES;\nSHOW PROFILE;",
      "RCA": "It looks like the latency is caused by how mv_activities is implemented in memsql, specifically: the amount of work and data transfer to materialize mv_activities is proportional to the size of the in-memory plancache, even if it doesn't return many rows\n\nThis is a known issue with the implementation of mv_activities and we're working on an improved design.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Configuration help",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7935",
      "Ticket Number": "#7935",
      "Title": "Ktymsqld Cluster Configuration",
      "EOG cluster": "ktymsqld",
      "Host": "n/a",
      "Solution": "Reconfig, Commands in commands collumn",
      "Commands": "memsql-ops memsql-update-config 5FD2751 --key maximum_memory --value 173000\nmemsql-ops memsql-list --memsql-role leaf -q | xargs -n 1 memsql-ops memsql-update-config --key maximum_table_memory --value 204480 --set-global\nmemsql-ops memsql-list --memsql-role leaf -q | xargs -n 1 memsql-ops memsql-update-config --key maximum_memory --value 227200 --set-global\nmemsql-ops memsql-optimize",
      "RCA": "Kérték, hogy csekkoljuk le, hogy a cluster jól lett-e beconfigurálva.\nNote: no restart is needed since values are only being increased.\nAlso is the following command correct? memsql-ops memsql-update-config 5FD2751 --key maximum_table_memory --value 154000, memsql-ops memsql-update-config --key maximum_memory --value 230.4G --set-global",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Grant migration from one cluster to an other",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7934",
      "Ticket Number": "#7934",
      "Title": "export/import all grants from one cluster to another cluster",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "./user_backup.sh -o outputfile.sql -h HOST -P PORT -u HOST -p PASSWORD\nmemsql -h HOST -P PORT -u HOST -p PASSWORD < outputfile.sql",
      "Commands": "./user_backup.sh -o outputfile.sql -h HOST -P PORT -u HOST -p PASSWORD # This will run SHOW GRANTS for each user and save them to the outfile. The user used in the parameters for the script must have permissions to view that user's grants if you want them in the outfile.\nmemsql -h HOST -P PORT -u HOST -p PASSWORD < outputfile.sql # This outfile can then be used to import the users, as with the below:",
      "RCA": "can you give us the procedure to export/import all USER grants from cluster to another cluster with passwords?\nCsatoltak hozzá egy user_backup.sh-t\nThe user used in the parameters for the script must have permissions to view that user's grants if you want them in the outfile.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "some one please check #8041",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8043",
      "Ticket Number": "#8043",
      "Title": "some one please check #8041",
      "EOG cluster": "",
      "Host": "ticked closed without action",
      "Solution": "",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "need to know the replicated databases",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7909",
      "Ticket Number": "#7909",
      "Title": "EOG - need to know the replicated databases",
      "EOG cluster": "ktymsqla18",
      "Host": "",
      "Solution": "Use the cluster report to see. Look for \"is replicating\" or run the following command on the master aggregator. Filter by REMOTE_NAME, everything that has a value is a replicated database.",
      "Commands": "select * from information_schema.distributed_databases;",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Removing Memsql from a cluster",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7916",
      "Ticket Number": "#7916",
      "Title": "Removing Memsql from a cluster",
      "EOG cluster": "",
      "Host": "",
      "Solution": "To entirely uninstall a MemSQL from a cluster, you can take the following steps. Note, these steps are to remove ALL nodes and complete destroy the cluster, not to simply remove a subset of nodes.\n\nBackup any data and credentials/grants you wish to save. Be extremely sure that you have saved everything you want to save.\nUse memsql-ops memsql-stop --all to shutdown the cluster. Should any nodes fail to shutdown, ssh in and kill -9 the memsqld processes.\nUse memsql-ops memsql-delete --all to delete all the nodes.\nDecide if you want to keep memsql-ops on the machines, or if you would like to uninstall that as well. If so, use memsql-ops agent-uninstall --all to remove all the Ops agents. Otherwise, keep Ops and reuse it to deploy new nodes for your tests.\nShould any of the above steps fail, and you plan to completely destroy this cluster, you can always physically delete the installation directories with a command similar to rm -rf /memsql.\n\nAt this point, you have deleted all the data in the cluster and uninstalled memsql and memsql-ops. To go one step further, you can search the system for any memsql related files that might have been left behind, but otherwise, you have completely deleted it.",
      "Commands": "memsql-ops memsql-stop --all, ssh in and kill -9 the memsqld, memsql-ops memsql-delete --all, memsql-ops agent-uninstall --all",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "not able to start OPS on one node. due to version mismatch",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7920",
      "Ticket Number": "#7920",
      "Title": "not able to start OPS on one node. due to version mismatch",
      "EOG cluster": "houmsql30",
      "Host": "",
      "Solution": "copy /var/lib/memsql-ops/data/memsql-ops-upgrade-v6-gate-flag from another leaf to this one",
      "Commands": "",
      "RCA": "After memsql upgrade a leaf failed to start. after restart they got \"Port 9000 is already bound, check that memsql-ops is not already running.\"  They killed and started ops and got  \"Expected AGENT_UPGRATE_V6_GATE_FLAG to exist. Please first upgrade to MemSQL Ops 5.8.\" This AGENT_UPGRATE_V6_GATE_FLAG  got deleted somehow. Copying  /var/lib/memsql-ops/data/memsql-ops-upgrade-v6-gate-flag from another leaf solved the issue.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "restore error",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7911",
      "Ticket Number": "#7911",
      "Title": "restore error",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Validate that all nodes have access, if not give them access, note: folder permissions might be needed in addtion to file permossions",
      "Commands": "touch /path/to/backup_dir/new_file.txt",
      "RCA": "ERROR 1790 (HY000): The path '/memsqlbackup/BACKUP/ie_dba/2019_03_31/2019_03_31__09_00/ie_dba.backup' is inaccessible or doesn't point to a MemSQL binary backup file Backup file must be accessable from every node on the cluster. If one fails all of the restotre fails. Validate that all nodes have access",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Long-running jobs",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8157",
      "Ticket Number": "#8157",
      "Title": "EOG Prod - ktymsql - jobs ran longer on evening of 2019-05-08",
      "EOG cluster": "ktymsql30",
      "Host": "Invalid cross-device link checking by eog' sysadmin\n memsql-ops restart needed to generate report",
      "Solution": "memsql-ops stop\n to access topology.db with following command: memsql-ops sqlite topology.db\n sqlite> delete from job_queue;\n sqlite> delete from intentions;\n sqlite> delete from intention_states;\n sqlite> delete from job_logs;\n .exit;\n memsql-ops start",
      "Commands": "good old cluster report check\n memsql-ops internal processes caused jobs queuing\n Invalid cross-device link found\n cat /Users/admin/Downloads/memsql-ops.log_05092019 | grep \"Invalid cross-device link:\" | tail\n a spam created tow db per second, probably causign perf issue\n before report generate memsql-ops stop/restart needs",
      "RCA": "past similar cases\n https://memsql.zendesk.com/agent/tickets/7575\n https://memsql.zendesk.com/agent/tickets/7624\n https://memsql.zendesk.com/agent/tickets/8085",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Cluster Configuration",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/8027",
      "Ticket Number": "#8027",
      "Title": "Houmsqlgng Cluster Configuration",
      "EOG cluster": "houmsqlgng87",
      "Host": "na",
      "Solution": "na",
      "Commands": "cluster report analysed on new cluster after install",
      "RCA": "only mentioned NUMA settings were not out of recommended, everything other was fine\n NUMA capacity exceeds the total host memory by 6 gigabytes. It isn't anything major but I thought I'd mention it to you.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Cluster Configuration",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7991",
      "Ticket Number": "#7991",
      "Title": "Houmsql Cluster Configuration",
      "EOG cluster": "houmsql11",
      "Host": "memory settings were needed",
      "Solution": "REMOVE LEAF 'houmsql14':3307;\n update the memory configs for all aggregators in the cluster:\n memsql-ops memsql-list -q -r aggregator master | xargs -L 1 memsql-ops memsql-update-config --key maximum_table_memory --value 103000\n memsql-ops memsql-list -q -r aggregator master | xargs -L 1 memsql-ops memsql-update-config --key maximum_memory --value 116000\n then memsql-ops memsql-restart ALLAGGREGATORIDS\n memsql-ops report --include-log-archives",
      "Commands": "good old cluster report analysed",
      "RCA": "correct leaf add syntax:\n ADD LEAF user[:'password']@'host'[:port] [INTO GROUP {1|2}];\n https://docs.memsql.com/sql-reference/v6.7/add-leaf/",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Long running insert",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7833",
      "Ticket Number": "#7833",
      "Title": "insert statement running longer",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "information_schema.processlist\n EXPLAIN [querry]",
      "RCA": "Long runnning querry, EXPLAIN-t is kértek\n WLDDPF_LPC is not equivalent on prod and stage.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "High memory consumption",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7793",
      "Ticket Number": "#7793",
      "Title": "EOG Prod : High memory consumption in 20 minute interval",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "information_schema.processlist\n memsql-ops memsql-list | grep -E 'MASTER|AGGREGATOR' | awk '{print $6,$7}' | while read host port; do mysql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"select * from information_schema.processlist;\" > /tmp/${host}_${port}_agg_processlist.txt;done\n memsql-ops memsql-list | grep LEAF | awk '{print $6,$7}' | while read host port; do mysql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"select * from information_schema.processlist;\" > /tmp/leaf_${host}_${port}_processlist.txt;done",
      "RCA": "High memory usafe van egy clusteren.\n Kértek egy information_schema.processlist-et.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Not able to run querry",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7774",
      "Ticket Number": "#7774",
      "Title": "EOG Prod - Not able to run select * from ipredict_prd_dba.z_hit_value",
      "EOG cluster": "ktymsqlb",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "memsql-ops memsql-update-config 645EFB9 --key maximum_table_memory --value 151946\n CLEAR ORPHAN DATABASES;",
      "RCA": "Nem fut le a querry.\n Issue detected: There is one long running query on the master aggregator that is blocking things up. Do you expect this query to run this long/indefinitely?\n + 2 node nem votl jól felconfigolva:\n max_table_memory too high for agent-A6f0285-ktymsqlb06-9000-follower-leaf/memsql-645EFB9-leaf-3307 (100% of max_memory) [168829/168829]\n max_table_memory too high for agent-A6f0285-ktymsqlb06-9000-follower-leaf/memsql-B0E94CC-leaf-3306 (100% of max_memory) [168829/168829]\n \n recommend to change max_table_memory 168829 => 151946\n Aztán CLEAR ORPHAN DATABASES;",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Delopying a leaf node",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7738",
      "Ticket Number": "#7738",
      "Title": "EOG - Prod - How to deploy a leaf node to a prexisting cluster (leaf was removed for maintenance)",
      "EOG cluster": "ktymsql27",
      "Host": "n/a",
      "Solution": "memsql-ops memsql-deploy --agent-id <AGENT_ID of host ktymsql27> --role leaf --port 3306 --availability-group 1",
      "Commands": "memsql-ops memsql-deploy --agent-id <AGENT_ID of host ktymsql27> --role leaf --port 3306 --availability-group 1\n memsql-ops memsql-update-config --key maximum_memory --value 116032 --set-global\n memsql-ops memsql-update-config --key maximum_table_memory --value 104428 --set-global",
      "RCA": "Node deployolása és configurálása",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Queing Querries",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7816",
      "Ticket Number": "#7816",
      "Title": "Memsql Performance Degraded",
      "EOG cluster": "houmsqliopt88",
      "Host": "n/a",
      "Solution": "Megnövleni a workload_management_max_connections_per_leaf",
      "Commands": "memsql-ops memsql-update-config --key workload_management_max_connections_per_leaf --value 7168 --set-global MEMSQL_ID",
      "RCA": "Yes we did find a misconfiguration: workload_management_max_connections_per_leaf has been reduced to only 4096. This directly causes the queuing you are seeing. Increasing it should reduce the queuing, and I confirmed that there should be sufficient resources in the cluster to increase it.\n \n Do you know why or when workload_management_max_connections_per_leaf was reduced? Its default value is 10,000.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Memory usage reached the value of 'maximum_table_memory'",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7780",
      "Ticket Number": "#7780",
      "Title": "Memory usage by MemSQL for tables (81921 MB) has reached the value of 'maximum_table_memory' global variable (81920 MB). This query cannot be execute",
      "EOG cluster": "ktymsql30",
      "Host": "ktymsql25:3309",
      "Solution": "Delete unused tables. If delete querys cannot run due to lack of memory then temporarily increase the size, Clear orphan databases",
      "Commands": "memsql-ops memsql-update-config --set-global --key maximum_table_memory --value INSERT_VALUE INSERT_MEMSQL_ID_OF_NODE, memsql -h ktymsql25 -P 3309 -u USER -p PASSWORD -e \"SHOW STATUS EXTENDED;\" | grep, memsql-ops memsql-update-config --set-global --key maximum_memory --value 122470 --allAlloc_table_memory, CLEAR ORPHAN DATABASES;",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Create a variable in a procedure that persists its value between calls",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7773",
      "Ticket Number": "#7773",
      "Title": "Create a variable in a procedure that persists its value between calls",
      "EOG cluster": "",
      "Host": "",
      "Solution": "No solution present at this time, workarounds are possible with temporary tables.",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "query causing aggregator to crash",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7749",
      "Ticket Number": "#7749",
      "Title": "EOG - Production - query causing aggregator to crash inside of OperatorWindowFunc 2019-03-12",
      "EOG cluster": "",
      "Host": "",
      "Solution": "memsql will fix any qeuries that crash a node",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Delete query failing with Leaf Error (ktymsql16:3307): Lock wait timeout exceeded; try restarting transaction",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7752",
      "Ticket Number": "#7752",
      "Title": "EOG PROD - Delete query failing with Leaf Error (ktymsql16:3307): Lock wait timeout exceeded; try restarting transaction",
      "EOG cluster": "ktymsql30",
      "Host": "ktymsql16:3307",
      "Solution": "get the process lists",
      "Commands": "mysql -h0 -uroot -pPASSWORDHERE -e 'show aggregators' | awk 'NR>1 {print $1,$2}' | while read host port; do mysql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"select * from information_schema.processlist;\" >  \n mysql -h0 -uroot -pPASSWORDHERE -e 'show leaves' | awk 'NR>1 {print $1,$2}' | while read host port; do mysql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"select * from information_schema.processlist;\" > /tmp/${host}_${port}_leaf_processlist.txt;done/tmp/${host}_${port}_agg_processlist.txt;done",
      "RCA": "Two modify queries were running on the same table at the same time causing a crash",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Application (iSupply) users are experiencing very slow response from the database",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7890",
      "Ticket Number": "#7890",
      "Title": "Application (iSupply) users are experiencing very slow response from the database",
      "EOG cluster": "",
      "Host": "",
      "Solution": "ticket closed without action",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Test Cluster creation follow-up",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7866",
      "Ticket Number": "#7866",
      "Title": "Re: Memsql Test Cluster",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "Pankaj, \n This is a small cluster and pushing from spark with multiple connections is not going to work. The writing should be a single thread. Any other way to push the data?",
      "Commands": "n/a",
      "RCA": "Follow up for #7865",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Test Cluster creation follow-up",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7860",
      "Ticket Number": "#7860",
      "Title": "RE: Memsql Test Cluster",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "n/a",
      "RCA": "n/a",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Test Cluster creation follow-up",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7859",
      "Ticket Number": "#7859",
      "Title": "Re: Memsql Test Cluster",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "n/a",
      "RCA": "Test clustert akartak létrehozni",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "PRTGP para",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7858",
      "Ticket Number": "#7858",
      "Title": "RE: [Houston C1] ktymsqld04 SNMP CPU Load (SNMP CPU Load) Down ESCALATION (No response (check: firewalls, routing, snmp settings of device, IPs, SNMP version, community, passwords etc) (SNMP erro...)",
      "EOG cluster": "ktymsqld04",
      "Host": "n/a",
      "Solution": "Updating the BIOS on this server that is why you are able to access it please ignore this alert.\n Herman or you, who should be working have to inform memsql_support whenever maintenance is done. There are PRTG alerting that makes us look at what went wrong.",
      "Commands": "n/a",
      "RCA": "Follow up for #7857 PRTGP para",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "PRTGP para",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7857",
      "Ticket Number": "#7857",
      "Title": "Re: [Houston C1] ktymsqld04 SNMP CPU Load (SNMP CPU Load) Down ESCALATION (No response (check: firewalls, routing, snmp settings of device, IPs, SNMP version, community, passwords etc) (SNMP erro...)",
      "EOG cluster": "ktymsqld04",
      "Host": "n/a",
      "Solution": "Updating the BIOS on this server that is why you are able to access it please ignore this alert.\n Herman or you, who should be working have to inform memsql_support whenever maintenance is done. There are PRTG alerting that makes us look at what went wrong.",
      "Commands": "n/a",
      "RCA": "Lehaltak a monitoolok",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Memsql Test Cluster",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7856",
      "Ticket Number": "#7856",
      "Title": "Memsql Test Cluster",
      "EOG cluster": "",
      "Host": "",
      "Solution": "ticked closed without action",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "How to write debug log entries from a procedure running in a read only cluster",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7750",
      "Ticket Number": "#7750",
      "Title": "How to write debug log entries from a procedure running in a read only cluster",
      "EOG cluster": "",
      "Host": "",
      "Solution": "I implemented what we needed by created a database on the Read Only cluster that is not replicated. Therefore, allowing me to write to the table from procedures running in the Read Only cluster.",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "ktymsql27 - evidence of disk malfunction on 2019-03-08",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7712",
      "Ticket Number": "#7712",
      "Title": "EOG - ktymsql27 - evidence of disk malfunction on 2019-03-08",
      "EOG cluster": "ktymsql30",
      "Host": "ktymsql27",
      "Solution": "ticked closed without action",
      "Commands": "",
      "RCA": "Disk health was poor",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "unkillable query inside of CompiledRegexp::MatchesReplace, Stored Procedure: CALL ie_dba.ie_force_key_metric_recalc()",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7677",
      "Ticket Number": "#7677",
      "Title": "EOG Prod - unkillable query inside of CompiledRegexp::MatchesReplace, Stored Procedure: CALL ie_dba.ie_force_key_metric_recalc()",
      "EOG cluster": "ktymsql30",
      "Host": "ktymsql11",
      "Solution": "Have to restart child aggregator that sent the query",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "convert 4 node to 2 node",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7804",
      "Ticket Number": "#7804",
      "Title": "convert 4 node to 2 node",
      "EOG cluster": "",
      "Host": "",
      "Solution": "#7643",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "KTYMSQLB query time out",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7528",
      "Ticket Number": "#7528",
      "Title": "EOG PRD - KTYMSQLB quert time out",
      "EOG cluster": "KTYMSQLB01",
      "Host": "",
      "Solution": "Long running queries caused the issue. Developer of said querys fixed them.",
      "Commands": "",
      "RCA": "The error is from reaching the threshold of length of time a query will queue before being dropped from the queue. It is configured by the workload_management_queue_timeout variable. When you reach this threshold, instead of adding another query to the queue it will raise ER_QUERY_QUEUE_TIMEOUT",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "How to enable database replication on read cluster",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7480",
      "Ticket Number": "#7480",
      "Title": "How to enable database replication on read cluster",
      "EOG cluster": "ktymsql30",
      "Host": "",
      "Solution": "https://docs.memsql.com/operational-manual/v6.7/using-replication/",
      "Commands": "",
      "RCA": "Additionally the user had access issues.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Availability group 2 has leaves in it. You must remove them before reducing the redundancy level.",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7469",
      "Ticket Number": "#7469",
      "Title": "ERROR 1784 (HY000): Availability group 2 has leaves in it. You must remove them before reducing the redundancy level.",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Follow the LEAF REMOVE_ADD document",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "How to backup tables, view, and stored procedures",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7441",
      "Ticket Number": "#7441",
      "Title": "EOG - How to backup tables, view, and stored procedures",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Run the given commands on the master aggregator and the whole DB.",
      "Commands": "The syntax is: mysqldump -uroot --protocol=socket -S /ebs/memsql/master-3306-MIfc1427ca/data/memsql.sock --host=localhost --lock-tables=false --no-data --databases memsql_demo --result-file=dump.sql --routines If you are not running it on the localhost then your syntax will be: mysqldump -uroot -p <password> --protocol=TCP --host=<YOUR_IP_HERE> -P <PORT> --lock-tables=false --no-data --databases memsql_demo --result-file=dump.sql --routines I want to draw your attention to three arguments that you'll need to take care to use. Most importantly is the --lock-tables=false argument because mysqldump will lock your tables and that's not what you want in this situation. The others are --protocol=socket and -S /ebs/memsql/master-3306-MIfc1427ca/data/memsql.sock. If you do not use those two arguments then you'll see the following error: mysqldump: Got error: 2002: Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2) when trying to connect This is because you're running a MySQL command so, by default, it is expecting mysqld.sock which isn't going to exist.",
      "RCA": "There is a script in the ticket for storing stored procedues as well",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "MemSQL Ops and Katy cluster",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7593",
      "Ticket Number": "#7593",
      "Title": "MemSQL Ops and Katy cluster",
      "EOG cluster": "",
      "Host": "",
      "Solution": "ticked closed without action",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Memory Configuration",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7881",
      "Ticket Number": "#7881",
      "Title": "EOG - houmsqlfin - misconfigured memory settings causing cluster to crash 2019-03-28",
      "EOG cluster": "houmsqlfin11",
      "Host": "",
      "Solution": "We will need to start each memsqld individually, drop slave partitions from the memsqld to free up memory, then repeat the same steps for each leaf until we have all master partitions online.",
      "Commands": "find . -name memsql_info.json | xargs grep -B1 -w maximum_memory | grep Value\n (1) Delete data or drop slave partitions on leaf nodes with alloc_table_memory greater than 77GB\n (2) Once all leaves are reporting under 77 GB for alloc_table_memory proceed.\n (3) Check Total_server_memory on all nodes and confirm Total_server_memory is less than 86 GB on all nodes\n (4) Once all leaves are reporting under 86 GB for Total_server_memory proceed.\n (5) Apply new configuration for maximum_memory and maximum_table_memory for all leaves:\n memsql-ops memsql-list --memsql-role leaf -q | xargs -n 1 memsql-ops memsql-update-config --key maximum_table_memory --value 77085\n memsql-ops memsql-list --memsql-role leaf -q | xargs -n 1 memsql-ops memsql-update-config --key maximum_memory --value 86721\n (6) Restart the cluster using memsql-ops memsql-restart --all\n drop slave partitions from leaf houmsqlfin18:3308\n restart slave partitions from leaf houmsqlfin18:3308\n DROP PARTITION landdm:12 ON 'houmsqlfin18':3308;\n DETACH LEAF 'houmsqlfin18':3308;\n memsql-ops memsql-restart 03E0649\n ATTACH LEAF 'houmsqlfin18':3308 NO REBALANCE;\n (1) connect to master aggregator\n (2) SET GLOBAL auto_attach = OFF\n (3) start memsql-ops memsql-start 03E0649, wait for houmsqlfin18:3308 to finish recovery\n (4) Attach leaf using ATTACH LEAF 'houmsqlfin18':3308 NO REBALANCE;\n (5) Generate a new cluster report and upload to ftp.\n then\n (2) Re-enable auto_attach:\n SET GLOBAL auto_attach = ON\n (3) Stop the entire cluster\n memsql-ops memsql-stop --all\n (4) start leafes\n memsql-ops memsql-start 03E064\n (5)\n start aggregator\n memsql-ops memsql-start agregator:leaf\n report generate\n (6)\n memsql-ops report\n ---\n after unvrecoverable partitions detected\n on master aggregator: SET GLOBAL attach_rebalance_delay_seconds = 604800;\n \"Do not run REBALANCE PARTITIONS \"\n Drop slave partitions to free memory in the cluster: like DROP PARTITION prdactdm:10 'houmsqlfin16':3307;\n on clsuter memsql-ops memsql-stop --all\n start some nodes and also the aggrreagtor as well:memsql-ops memsql-start 4662C3\n wait 5 mn to memsql-ops report\n considerabel memory usage on async slaves to drop: DROP PARTITION LPC_ADM:25 ON 'houmsqlfin16':3306;\n update the memsql.cnf of all leaves to raise the maximum_memory limit:\n memsql-ops memsql-list --memsql-role leaf -q | xargs -n 1 memsql-ops memsql-update-config --key maximum_memory --value 140000\n update the memsql.cnf of all leaves to raise the maximum_table_memory limit:\n memsql-ops memsql-list --memsql-role leaf -q | xargs -n 1 memsql-ops memsql-update-config --key maximum_table_memory --value 126000\n after this set stop all leaf and restart only leafs with aggregator\n --1 db needed to drop to get neough memo finally then set new key values:\n memsql-ops memsql-list --memsql-role leaf -q | xargs -n 1 memsql-ops memsql-update-config --key maximum_table_memory --value 77085\n memsql-ops memsql-list --memsql-role leaf -q | xargs -n 1 memsql-ops memsql-update-config --key maximum_memory --value 86721\n memsql-ops memsql-stop --all\n memsql-ops memsql-start --all\n on master aggregator SET GLOBAL attach_rebalance_delay_seconds = 120;\n EXPLAIN CLEAR ORPHAN DATABASES;\n  CLEAR ORPHAN DATABASES;\n some lead did not get the memo update becasue they were not restarted,so\n memsql-ops start/stop on cluster with node force restart by ops ( by stopping them )\n sudo -u memsql /var/lib/memsql/leaf-3309-MIe302a73e/service stop\n after memo config is correcet max conn threads adjust comes on all leafs:\n memsql-ops memsql-list --memsql-role leaf -q | xargs -n 1 memsql-ops memsql-update-config --key max_connection_threads --value 8192 --set-global\n two additional correction on Master and Child aggregator :\n memsql-ops memsql-update-config 4662C38 --key maximum_table_memory --value 231000\n with its restart: memsql-ops memsql-restart \"id\"\n in case of partition (Could not get SHOW TABLE STATUS FROM) has no master instance -pending status - manually attach them\n on master aggregator attach ATTACH PARTITION landdm:3 ON 'houmsqlfin15':3309\n then rebalance partitions:\n rebalance partitions on IFILE_DBA;",
      "RCA": "cluster report analyse\n leafs memory configured exceeded total size\n one db detected as corrupt\n partition on db's cluster failed to replay due to insufficient memory:\n Partitions - ones that have not enough memory to recover - and slave dbs should have been dropped to free more memory\n from Master partitions data deletion needs to set correct memory settings\n after drop slave partitions",
      "Comments": "Each host has capacity of 385427 GB\n Each host has 4 leaves installed\n 385427/4 = 96,356.75\n 96,356.75*.9 = 86,721 (recommended maximum_memory per leaf)\n 96,356.75*.8 = 77,085 (recommended maxmimum_table_memory per leaf)\n https://docs.memsql.com/concepts/v6.7/data-skew/\n I recommend setting max_connection_threads to 8192 on all leaves\n you can use max_connection_threads set to 1024 on all aggregators\n in case of offline agent this error message is displayed: \"MemSQL node does not have an online colocated agent.\":memsql-ops start command should be run on leaf",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "",
      "Ticket Link": "",
      "Ticket Number": "",
      "Title": "",
      "EOG cluster": "",
      "Host": "",
      "Solution": "",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Pipeline error",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7988",
      "Ticket Number": "#7988",
      "Title": "EOG - Pipeline error Row 1 was truncated",
      "EOG cluster": "n/a",
      "Host": "",
      "Solution": "advise to check pipeline",
      "Commands": "json error msg analysis",
      "RCA": "Data being received had more columns than the table in MemSQL they were being ingested in to. I’d recommend checking your source, extractor, and transform to see if it changes the existence of a column (or adds a column) at any point.",
      "Comments": "https://docs.memsql.com/memsql-pipelines/v6.7/kafka-pipeline-quickstart/",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Lock Promote",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7944",
      "Ticket Number": "#7944",
      "Title": "LOCK PROMOTE failed because the database landdm_43 is missing blob files due to replication lag",
      "EOG cluster": "ktymsqlfin16",
      "Host": "",
      "Solution": "create a connection directly into leaf and there run the _repair table command\n bug fix was released for this issue",
      "Commands": "DROP PARTITION landdm:43 ON 'ktymsqlfin16':3309;\n COPY PARTITION landdm:43 TO 'ktymsqlfin16':3309;\n create a connection directly into leaf and there run the _repair table command",
      "RCA": "leaf takedown casued lock promote/replication lag message\n report analysis:\"This lag in replication is normal and expected in an async replicated database.\"\n leaf detached with only on one leaf was problematic,columnar files were missing\n drop and then copy problematic partition\n aggressive workload hit impacted that one partition,async slave has missing columnar files, that is the reason to not able detach\n check for missing columnar run EXPLAIN _REPAIR_TABLE dbname.tablenames;\n repair table feature does not work on non-columnstore tables, this should be run on leaf",
      "Comments": "From EOG: We do not keep memsql.log going back two months we only have a months worth of logs.\n https://docs.memsql.com/release-notes/latest/67-release-notes/#2019-03-25-version-6-7-15",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Enable local-infile option",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7929",
      "Ticket Number": "#7929",
      "Title": "Enable local-infile option memsql",
      "EOG cluster": "n/a-test",
      "Host": "",
      "Solution": "na-not shared how changed parameter for load command",
      "Commands": "Error caused by : LOAD DATA LOCAL INFILE \"/home/memsql/sample.csv\" INTO TABLE t (id);",
      "RCA": "load data failed and messaged: \n \"ERROR 1148 (42000): LOAD DATA LOCAL is disabled by your client configuration. You can enable it in the mysql client with the --local-infile option. See https://dev.mysql.com/doc/refman/en/load-data-local.html for more information.\"\n Client was asked for but not shared this info",
      "Comments": "https://dev.mysql.com/doc/refman/8.0/en/load-data-local.html",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Slow response time",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7893",
      "Ticket Number": "#7893",
      "Title": "Re: very slow response time on ktymsqlfin11.eogresources.com memsql server, iSupply Production user complaining",
      "EOG cluster": "ktymsqlfin11",
      "Host": "",
      "Solution": "na,no follow-up for memsql vendor question",
      "Commands": "memsql-ops memsql-list",
      "RCA": "report analysis;\n more precise issuse description about \"slowness\" asked for\n  long-running, sleeping threads which have open transactions and are holding row locks. Is the verdict\n looks like transactions remained opened without commit, asked for this behaviour\n also probably some kind of theirs docker ( for their loads) might not commit after fetch data\n no answer delivered",
      "Comments": "follow-up to your previous request #7891",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Leaf reduce",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7643",
      "Ticket Number": "#7643",
      "Title": "EOG Prod - changing leafs on all nodes from 4 to 2",
      "EOG cluster": "KTYMSQL30",
      "Host": "",
      "Solution": "NO DOCUMENTED/CONFIRMED steps only information share\n MemSQL Professional Services team engagement was mentioned to tailor change\n then to wait on Krishna's commands.",
      "Commands": "memsql-ops memsql-list \n memsql-ops agent-list\n Advised steps to decrease leafes\n Before we run through any steps to remove leaves, I would like to first pair two nodes on port 3306 and 3307 that are currently paired with nodes on 3308.\n \n Here's the current pairings:\n \n ``` \n | ktymsql14 | 3308 | 2 | ktymsql15 | 3306 | online | 33 | 0.29 | \n | ktymsql15 | 3308 | 1 | ktymsql14 | 3307 | online | 33 | 0.28 | \n ```\n \n The goal is to pair\n \n ``` \n ktymsql15:3306 --> ktymsql14:3307 \n ktymsql14:3308 --> ktymsql15:3308 \n ```\n \n This will make the leaf removal process much simpler.\n \n 1. enable ops manual control `$ memsql-ops cluster-manual-control --enable` \n 1. stop ktymsql15:3306 and allow failover to complete: `$ memsql-ops memsql-stop 437E60FB460F867D3437F47B440BA623BC490DD6` \n 2. connect to the master aggregator and remove the leaf `memsql> remove leaf 'ktymsql15':3306;` \n 3. re-add the leaf into AG 2 `memsql> add leaf root:'ROOTPASS'@'ktymsql15':3306 into group 2;` \n 4. stop ktymsql14:3307 and allow failover to complete: `$ memsql-ops memsql-stop C3FD99DC072CA7E008A5CB48EB0F0B194CF237A2` \n 5. connect to the master aggregator and remove the leaf `memsql> remove leaf 'ktymsql14':3307;` \n 6. re-add the leaf into AG 1 `memsql> add leaf root:'ROOTPASS'@'ktymsql14':3307 into group 1;` \n 7. connect to the master aggregator and remove the leaf `memsql> remove leaf 'ktymsql15':3308;` and allow the data to be rebalanced in the cluster (this will happen automatically) \n 8. re-add the leaf into AG 1 `memsql> add leaf root:'ROOTPASS'@'ktymsql15':3308 into group 1;` \n 9. diable ops manual control `$ memsql-ops cluster-manual-control --disable` \n 9. check the output of `memsql> SHOW LEAVES;` to make sure the leaves are now paired as we want \n 9. run `memsql> EXPLAIN REBALANCE PARTITIONS ON db_name;` for all your databases to make sure all data is balanced (I do expect there to be some orphans) \n 10. run `memsql> REBALANCE PARTITIONS ON db_name;` for the databases that need to be rebalanced\n \n test memsql db was created to explore above scenarios\n General procedure was sent:\n the operation to remove leaves and allow their data to be redistributed to the other nodes in the cluster is the REMOVE LEAF command:\n \n https://docs.memsql.com/sql-reference/v6.7/remove-leaf/\n \n General steps for you to test with would be:\n \n Check memory and disk usage of the host\n REMOVE LEAF '10.4.198.112':3309\n Wait for rebalancing to complete and check memory and disk usage again\n REMOVE LEAF '10.4.198.112':3308\n Wait for rebalancing to complete and check memory and disk usage again\n Ensure data has been cleaned up and memory and disk is the same as it was at the beginning of the process (before the removals)",
      "RCA": "leaf reduction from 4 to 2 was requested based on MemSQL suggestion\n partition reduce done by eog people before test sys change\n only two port wanted to remain",
      "Comments": "leafs/partition ratio is important, partitions can divide by 32 so the partitions will be evenly distributed to all leaves.",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Execute privilege grant",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7925",
      "Ticket Number": "#7925",
      "Title": "grant any execute to a user",
      "EOG cluster": "n/a-prd",
      "Host": "",
      "Solution": "Execute privilege set",
      "Commands": "GRANT EXECUTE ON `database_name`.`function_name` TO 'user_name'@'host_name';",
      "RCA": "request description cleared need",
      "Comments": "https://docs.memsql.com/sql-reference/v6.7/permissions-matrix/",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Oom killer",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7861",
      "Ticket Number": "#7861",
      "Title": "EOG - ktymsqlb07:3307 and ktymsqlb09:3307 killed by linux oom killer",
      "EOG cluster": "ktymsqlb01",
      "Host": "",
      "Solution": "na,no follow-up for memsql vendor question",
      "Commands": "memsql-ops memsql-list \n memsql-ops agent-list\n send output of dmesg -T",
      "RCA": "after list display report asked for investigate\n Each numa node has a capacity of about 195 GB:\n probably memo usage reached numa capacity\n no operation detected with app from report that would cause high memo usage\n suggested steps\n start ktymsqlb07:3307\n wait for ktymsqlb07:3307 to finish recovery. Once recovery is finished proceed.\n start ktymsqlb09:3307\n wait for ktymsqlb09:3307 to finish recovery.\n When both leaves have finished recovery and automatically attached back into the cluster please generate a second cluster report.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Slow response time",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7891",
      "Ticket Number": "#7891",
      "Title": "very slow response time on ktymsqlfin11.eogresources.com memsql server, iSupply Production user complaining",
      "EOG cluster": "ktymsqlfin11",
      "Host": "",
      "Solution": "n/a",
      "Commands": "n/a",
      "RCA": "n/a",
      "Comments": "followed in #7893",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Access denied for user 'eor_dba'@'localhost' (using password: YES)",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7277",
      "Ticket Number": "#7277",
      "Title": "ERROR 1045 (28000): Access denied for user 'eor_dba'@'localhost' (using password: YES)",
      "EOG cluster": "ktymsqlstg31",
      "Host": "",
      "Solution": "https://docs.memsql.com/security/v6.7/synchronize-permissions/ or check if user eor_dba exsits on all of the CA. If not create it",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "MemSQL Node Keeps Rebooting",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7274",
      "Ticket Number": "#7274",
      "Title": "MemSQL Node Keeps Rebooting",
      "EOG cluster": "ktymsqlb01",
      "Host": "",
      "Solution": "Hardware failure",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Timeout expired @memsql@ktymsqlstg31",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7252",
      "Ticket Number": "#7252",
      "Title": "error connecting: Timeout expired @memsql@ktymsqlstg31",
      "EOG cluster": "ktymsqlstg31",
      "Host": "",
      "Solution": "Not a memsql error, the database connector is faulty",
      "Commands": "",
      "RCA": "High latency on nodes",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Bad distributed join plan: leaf select contains sharded tables of multiple databases. Please contact technical support",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7159",
      "Ticket Number": "#7159",
      "Title": "memsql Error Code: 1889. Bad distributed join plan: leaf select contains sharded tables of multiple databases. Please contact technical support",
      "EOG cluster": "",
      "Host": "",
      "Solution": "MemSql issue should be fixed in version 7",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "recovery failed after server recovered from bad memory",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7171",
      "Ticket Number": "#7171/A",
      "Title": "EOG STG - recovery failed after server recovered from bad memory",
      "EOG cluster": "ktymsqlstg31",
      "Host": "",
      "Solution": "stop all the leaves on the host, delete the plan refereing to every table that the query use after ftp to it, alternatie solution is to delete the entire nodes plancash at /path/to/leaf/data/plancache",
      "Commands": "",
      "RCA": "Query did not coplie due to code error. Need to remove query from the plancache",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Node complety unaccessble",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7171",
      "Ticket Number": "#7171/B",
      "Title": "EOG STG - recovery failed after server recovered from bad memory",
      "EOG cluster": "ktymsqlstg31",
      "Host": "",
      "Solution": "Remove the dead leaves with force command, switch to master aggregator remove dead leaves from monitoring, remove leaves from database, deploy a new host, stop it, edit  settings.conf file at /var/lib/memsql-ops/settings.conf, start the new agent, replace lost leaves, check on rebalance partitions command, if everything is okay run it, (might need to use force)",
      "Commands": "REMOVE LEAF 'host':port [FORCE], memsql-ops memsql-unmonitor DEAD_LEAF_ID, REMOVE LEAF 'ktymsqlstg40.eogresources.com':port FORCE; memsql-ops agent-deploy --host HOST_IP, memsql-ops agent-stop NEW_AGENT_ID, memsql-ops agent-start NEW_AGENT_ID, memsql-ops memsql-deploy --agent-id NEW_AGENT_ID --role leaf, EXPLANE REBALANCE PARTITIONS ON db_name FORCE; REBALANCE PARTITIONS ON db_name FORCE;",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Rebalancing partitions caused the master aggregator to crash",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7171",
      "Ticket Number": "#7171/C",
      "Title": "EOG STG - recovery failed after server recovered from bad memory",
      "EOG cluster": "ktymsqlstg31",
      "Host": "",
      "Solution": "Drop the database and restore it from backup. This bug should be fixed in version 6.7.8",
      "Commands": "",
      "RCA": "The tables had a computed column",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "memsql-ops process repeatedly being shut down",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7575",
      "Ticket Number": "#7575",
      "Title": "EOG - Ops process repeatedly being shut down. Unknown which process is stopping Ops.",
      "EOG cluster": "ktymsql30",
      "Host": "",
      "Solution": "temporary solution was:\n rc.local file change to start ops first\n update memsql-ops' `settings.conf` file, adding the line `max_analytics_ttl=0`, then restart primary agent\n from the ops UI, we unchecked the box next to `MemSQL Schema Monitoring`.\n (What this change has done is disable MemSQL Ops' analytics function.)->no cpu/memo info in UI\n solution:\n invalid cross-device link removal\n then reenable Schema Monitoring, remove max_analytics_ttl from settings.conf and restart the ops primary agent",
      "Commands": "search for systemctl config changes: sudo systemctl list-units | grep memsql-ops\n sudo journalctl -u memsql-ops.service -b > ops.log;\n to eliminate Could not reach local agent error msq for memsql/agent-list:\n (1) SSH into 10.4.55.30\n (2) Stop the primary ops agent running on 10.4.55.30 by running memsql-ops stop\n (3) check ps to confirm no ops processes are running\n (4) Open the topology.db file on 10.4.55.30 in the Ops data dir with following command: memsql-ops sqlite topology.db\n (5) Run the following commands:\n \n sqlite> delete from job_queue;\n sqlite> delete from intentions;\n sqlite> delete from intention_states;\n sqlite> delete from job_logs; \n (6) exit sqlite using following command: .exit\n (7) start Ops primary agent with following command: memsql-ops start\n \n After doing steps 1-5 please let me know if you are still hitting this issue:\n for info gather about :last -x reboot\n update memsql-ops' `settings.conf` file, adding the line `max_analytics_ttl=0`,\n temporary solution was:\n rc.local file change to start ops first\n update memsql-ops' `settings.conf` file, adding the line `max_analytics_ttl=0`, then restart primary agent\n from the ops UI, we unchecked the box next to `MemSQL Schema Monitoring`.\n (What this change has done is disable MemSQL Ops' analytics function.)->no cpu/memo info in UI",
      "RCA": "from report restarted nodes detected\n plus some disk were almost full-storage issze\n memsql-ops.log was not pointed to installation directory\n In that ticket we discussed how this cluster is configured to store more data on disk due to increasing the snapshots_to_keep from the default of 2 to 8, which will store 8 full snapshots on disk before removing them and how this cluster is also configured with an increased value for the size of a snapshot (snapshot_trigger_size) which is 8x higher than our default.\n This setting was requested during DR \n on some nodes memsql was not started as root\n experiment fo find out what is happening @ stopping memsql-ops:\n memsql ops pid find: ps aux | grep ops\n then with Gnu Debugger GDB - install needs on master - as parameter feed memsql-ops pid\n wait till ops prim agent stops\n gdb info for several kills: kill/sigkill_kill -ABRT/SIGABRT_kill -15/SIGTERM\n after manual ops restart:\n \"(gdb) continue \n Continuing.\n Program received signal SIGPIPE, Broken pipe. \n [Switching to Thread 0x7f2da8ec2700 (LWP 266189)] \n 0x00007f2dbae6299b in send () from /lib64/libpthread.so.0 \"\n after stop gdb should bt-d to \"\n //Running bt in gdb after the program crashes will provide us with a stack dump at the time of crash that will help us debug why the process is crashing.\"\n or run bt full\n memsql.ops log file should come from master aggregator\n automatic ops satrt/stop process/program was asked with topology.db file from ops/data folder to investigate\n \"apsw.LockedError: LockedError: database table is locked\" comes from log, makes multiple ops suspect in system\n checked for agent start script at here:/etc/rc.d/rc.local.\n su memsql -c \"/var/lib/memsql-ops/memsql-ops start\" was placed on first line but not helped\n OS change in éast 30 days was asked for\n healthy disk usage was asked\n temporary solution was:\n rc.local file change to start ops first\n update memsql-ops' `settings.conf` file, adding the line `max_analytics_ttl=0`, then restart primary agent\n from the ops UI, we unchecked the box next to `MemSQL Schema Monitoring`.\n (What this change has done is disable MemSQL Ops' analytics function.)->no cpu/memo info in UI\n EOG wanted back analytics but revert above two steps caused crash again:\n memsql-ops.log has full of invalid cross-device link msgs\n drive change happened in another cluster not sure that caused stop, because since that no crash reported",
      "Comments": "same issue in #7576.\n The amount of disk being used by memsql logs/snapshots was a decision made in ticket #7006.\n recommended one of best practicies https://docs.memsql.com/tutorials/v6.5/installation-best-practices/#configure-linux-vm-settings\n invalid cross-device link issue was also in 7624",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "high availability cluster bring down",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7722",
      "Ticket Number": "#7722",
      "Title": "Provide Steps to bring KTYMSQL27 offline which is having High availability",
      "EOG cluster": "ktymsql30",
      "Host": "ktymsql27",
      "Solution": "n/a, possibel online memsql docu - in comments - helped eog infra team bring back leaf",
      "Commands": "n/a",
      "RCA": "info was shared in ticket",
      "Comments": "https://docs.memsql.com/operational-manual/v6.7/taking-leaves-offline-without-cluster-downtime/ https://docs.memsql.com/operational-manual/v6.7/dealing-with-failures/#step-4-deploy-a-new-memsql-leaf",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "test-cluster",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7868",
      "Ticket Number": "#7868",
      "Title": "RE: Memsql Test Cluster",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "n/a",
      "RCA": "hive and spark write not worked\n test cluster created and loaded data into:\n The test cluster you requested are finished.\n 10.4.198.111 Master:3306\n 10.4.198.112. Leaf:3306,3307,3308,3309\n Users: root/eogtestmemsql and memsql/memsql\n Muhammad Ali",
      "Comments": "follow-up to your previous request #7867 \"RE: Memsql Test Cluster",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "test-cluster",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7867",
      "Ticket Number": "#7867",
      "Title": "RE: Memsql Test Cluster",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "n/a",
      "RCA": "hive and spark write not worked\n test cluster created and loaded data into:\n The test cluster you requested are finished.\n 10.4.198.111 Master:3306\n 10.4.198.112. Leaf:3306,3307,3308,3309\n Users: root/eogtestmemsql and memsql/memsql\n Muhammad Ali",
      "Comments": "same as #7868 but its originated from 7866",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "long running queries",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7651",
      "Ticket Number": "#7651",
      "Title": "EOG Prod- Cluster running very slow from last 2 hours - 2019-02-27",
      "EOG cluster": "ktymsql30",
      "Host": "n/a",
      "Solution": "killed queries",
      "Commands": "Run the following one-liner from the master aggregator to query all aggregators for the contents of their information_schema.processlist, which will show us what is currently running on the aggregators.\n Please run these commands and send the result file created in /tmp to us via this ticket. Be sure to substitute the PASSWORDHERE in the commands, if there is a password.\n memsql-ops memsql-list | grep -E 'MASTER|AGGREGATOR' | awk '{print $6,$7}' | while read host port; do mysql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"select * from information_schema.processlist;\" > /tmp/${host}_${port}_agg_processlist.txt;done\n Then, run the following one-liner from the master aggregator in a cluster to query all leaves for the contents of their information_schema.processlist.\n memsql-ops memsql-list | grep LEAF | awk '{print $6,$7}' | while read host port; do mysql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"select * from information_schema.processlist;\" > /tmp/leaf_${host}_${port}_processlist.txt;done\n memsql-ops memsql-list | grep -E 'MASTER|AGGREGATOR' | awk '{print $6,$7}' | while read host port; do mysql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"select * from information_schema.mv_queries;\" > /tmp/${host}_${port}_agg_processlist.txt;done \n collect the processlist manually with the below command:\n ``` \n $ mysql -h0 -uroot -pPASSWORDHERE -e 'show aggregators' | awk 'NR>1 {print $1,$2}' | while read host port; do mysql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"select * from information_schema.processlist;\" > /tmp/${host}_${port}_agg_processlist.txt;done \n $ mysql -h0 -uroot -pPASSWORDHERE -e 'show leaves' | awk 'NR>1 {print $1,$2}' | while read host port; do mysql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"select * from information_schema.processlist;\" > /tmp/${host}_${port}_leaf_processlist.txt;done \n Without MemSQL Ops, you can collect the backtrace manually with the below command:\n \n ``` \n $ mysql -h0 -uroot -pPASSWORDHERE -e 'show aggregators' | awk 'NR>1 {print $1,$2}' | while read host port; do mysql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"_bt;\" > /tmp/${host}_${port}_agg_backtrace.txt;done \n $ mysql -h0 -uroot -pPASSWORDHERE -e 'show leaves' | awk 'NR>1 {print $1,$2}' | while read host port; do mysql -uroot -h${host} -pPASSWORDHERE -P${port} -e \"_bt;\" > /tmp/${host}_${port}_leaf_backtrace.txt;done \n ```",
      "RCA": "check for long running queries\n killed those and then cluster run fine\n but this did not solve problem\n processlist and backtrace was asked after next incident happens",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "leafs remained offline",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7624",
      "Ticket Number": "#7624",
      "Title": "EOG Prod - all memsql leaf nodes down on host ktymsql27 for 2 hours on 2019-02-24",
      "EOG cluster": "ktymsql30",
      "Host": "ktymsql27",
      "Solution": "rejoin host then simple start leafs, that was made by ops automatically\n plus rebalanced partitions\n root cause not detected: dmp.stack file or core file not generated, these are made when memsql itself crashes",
      "Commands": "memsql-ops memsql-start\n advise step to see rebalance was still needed:EXPLAIN REBALANCE PARTITIONS ON [database name]\n last -x reboot",
      "RCA": "IF Ops still showing things as offline on ktymsql27? If so will you ssh to ktymsql27 and run memsql-ops stop and then memsql-ops start. If that doesn't work you can also find memsql-ops's PID with ps aux | grep memsql-ops and do a sudo kill -9 <PID> to kill the memsql-ops process and then try to run memsql-ops start\n global host issue suspect, because all node start uptime muchmuch lower than other nodes\n leafs went offline for 2 hours\n  It looks like vm.max_map_count is misconfigured on multiple hosts in the cluster ( it is set to 100 million). vm.max_map_count should be set to 1 billion.\n infrastrucutre team invvolvement needed to heal host\n dmesg report asked for\n filesystem malfunction detected also: \n [ 609.337379] EXT4-fs error (device dm-1): ext4_lookup:1441: inode #181421482: comm memsqld: deleted inode referenced: 181421768\n there was also Invalid cross-device link in log when issue happened\n EOG detected file system repair needs - steps shared\n disk repair run no issue confirmed",
      "Comments": "https://docs.memsql.com/sql-reference/v6.7/rebalance-partitions/ https://docs.memsql.com/installation/v6.7/system-requirements/#configure-linux-vm-settings https://docs.memsql.com/memsql-ops/v6.7/taking-leaves-offline-without-cluster-downtime/",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Partition has no master instance",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7591",
      "Ticket Number": "#7591",
      "Title": "EOG - CRITICAL:2019-02-20 13:50:11,894:(1777, 'Partition ie_dba:16 has no master instance.')",
      "EOG cluster": "prd",
      "Host": "n/a",
      "Solution": "n/a-probably gone",
      "Commands": "dmesg -T for network related issue detect",
      "RCA": "Proactive steps:Going to upload cluster report and output of !) Show partitions on ie_dba 2) show cluster status and 3) select * from information_schema.DISTRIBUTED_PARTITIONS\" in a file called clusterstts.txt\n cluster not being configured for high availability\n asked for new report after getting the same next error msg with\"Show partitions on [whatever database is mentioned in the errors]\n show cluster status",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Partition has no master instance",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7547",
      "Ticket Number": "#7547",
      "Title": "Ă˘â‚¬Ĺ›SQL Error [1777] [HY000]: Partition ie_mirror_dba:1 has no master instance.Ă˘â‚¬ĹĄ",
      "EOG cluster": "",
      "Host": "n/a",
      "Solution": "HA enable and rebalance db helped but\n leafs moved to same availability groups\n clear orphane dbs",
      "Commands": "`memsql> show partitions on ie_mirror_dba extended;` and `memsql> show cluster status;`.\n 1. Connect to the master aggregator and send the output from `select * from information_schema.DISTRIBUTED_PARTITIONS` \n 2. Create a cluster report pre-restart \n 3. Restart the master aggregator `memsql-ops memsql-restart memsql_id_of_ma` \n 4. Create a cluster report post-restart\n --\n SHOW CLUSTER STATUS;\n HA set and rebalance db;\n explain \"and/or\" clear orphan databases\n enable cluster manual control to not put back leaf into groups then\n ##remove 'ktymsqlb03':3307 in AG 2 \n memsql> REMOVE LEAF 'ktymsqlb03':3307 FORCE;\n ##remove 'ktymsqlb09':3306 in AG 1 \n memsql> REMOVE LEAF 'ktymsqlb09':3306 FORCE;\n ##Add it back into AG 1 \n memsql> ADD LEAF user:'password'@'ktymsqlb03':3307 INTO GROUP 1;\n ##Add 'ktymsqlb09':3306 to AG 2 \n memsql> ADD LEAF user:'password'@'ktymsqlb09':3306 INTO GROUP 2;\n ##remove 'ktymsqlb10':3307 in AG 1 \n memsql> REMOVE LEAF 'ktymsqlb10':3307 FORCE;\n ##remove 'ktymsqlb08':3306 in AG 2 \n memsql> REMOVE LEAF 'ktymsqlb08':3306 FORCE;\n ##Add it back into AG 2 \n memsql> ADD LEAF user:'password'@'ktymsqlb10':3307 INTO GROUP 2;\n ##Add 'ktymsqlb08':3306 to AG 1 \n memsql> ADD LEAF user:'password'@'ktymsqlb08':3306 INTO GROUP 1; \n max memo set\n memsql-ops memsql-update-config --key maximum_memory --value 346875 --set-global 43690FC \n follower agents restart needed by connecting to each host in the cluster and running memsql-ops restart.\n memsql-ops restart. on prim agent",
      "RCA": "two slave was read for ie_mirror_dba\n only slave partitions were listed, master aggregator restart was advised to promote partitions accordingly\n The root problem we're examining now is why show databases extended is showing 2 slaves for the same partition:\n whereas show partitions is showing the correct states:\n high availability was disabled and re-enabled, that caused this phenomenon\n after HA enabled rebalance db solved issue\n SHOW LEAVES delivered leaves should be in the same availability group. \n handle orphan tables:\n connect to the master aggregator and run\n \n ``` \n memsql> use ipredict_prd_dba;\n \n memsql> desc r_compare_hits; \n memsql> desc r_entity_treeview_cache; \n memsql> desc r_entity_treeview_cache_update; \n memsql> desc r_h2o_prod; \n memsql> desc r_offset_psi_before; \n memsql> desc r_water_prod; \n memsql> desc z_offset_psi_update; \n ```\n When you run the above commands do you get an error like\n ``` \n ERROR 1146 (42S02): Table <TABLE_NAME> doesn't exist \n ```\n Please send me which table names generate the above warning.\n There are some tables exist on your leaf nodes that do not exist in the master aggregator's \n These tables will need to be removed from each leaf manually.\n \n 1. Connect to `ktymsqlb04:3306` with the mysql client and run\n \n ``` \n DROP TABLE IF EXISTS ipredict_prd_dba_105.z_offset_psi_update; \n topology.db collected: The default location of the topology.db should be in /var/lib/memsql-ops/data",
      "Comments": "Tables can only be dropped from master partitions. \n leaves should be in the same availability groups\n In this case we get \"The database 'ipredict_prd_dba_28' is in the 'replicating' state and is thus not available for writes.\" msg",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Connect memsql to ADO.net",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7543",
      "Ticket Number": "#7543",
      "Title": "Need to Connect MemSQL using ADO.net Driver",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "memsql -h HOSTNAME -P PORT -u USER -pPASSWORD",
      "RCA": "Could not conenct, valszeg a TIBCO nem supportálta, azóta nem lett semmi",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Point in time / Restore table",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7273",
      "Ticket Number": "#7273",
      "Title": "EOG - Point in time restore/recovery needed",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "Command",
      "Commands": "SELECT * FROM table \nAS OF TIMESTAMP \nTO_TIMESTAMP('2019-01-30 13:33:00', 'YYYY-MM-DD HH:MI:SS')",
      "RCA": "Point of time bacupot szerettek volna kreálni, restore a table few hours back",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Addig new leaf + optimize",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7546",
      "Ticket Number": "#7546",
      "Title": "Adding a new node to existing cluster",
      "EOG cluster": "ktymsqlb01",
      "Host": "n/a",
      "Solution": "Commands",
      "Commands": "master-agg-and-leaf-ip-10-0-3-209 /home/admin $ memsql-ops memsql-update-config --key maximum_memory --value 12000\nmaster-agg-and-leaf-ip-10-0-3-209 /home/admin $ memsql-ops memsql-update-config --key maximum_table_memory --value 10000\nmaster-agg-and-leaf-ip-10-0-3-209 /home/admin $ memsql-ops memsql-optimize --memory-percentage 90",
      "RCA": "A leaf saját magával állt párban. Újraadták már máshogy állt párba. Config jó-e azt kérdezték",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Snapshot using 290 GB memo",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7576",
      "Ticket Number": "#7576",
      "Title": "EOG - transaction logs using 172 GB and snapshot using 280 GB on a leaf node - snapshots_to_keep=8",
      "EOG cluster": "ktymsql15",
      "Host": "n/A",
      "Solution": "8-ról 2 re állítóttták a snapshots_to_keep et",
      "Commands": "agent-A34700d-ktymsql15-9000-follower-leaf$ find . -name memsql.cnf | xargs grep \"snapshots_to_keep\"\nsnapshots_to_keep = 2",
      "RCA": "Túl sok memót használt a snapshot, 8-ra volt állítva, a default 2",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Workbenc unable to connect to memsql",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7294",
      "Ticket Number": "#7294",
      "Title": "EOG - MySQL Workbench 8.0 unable to connect to memsql",
      "EOG cluster": "n/s",
      "Host": "n/s",
      "Solution": "Jegyben kép elmagyarázza hogyan kell",
      "Commands": "Connection > Advanced and enter defaultAuth=mysql_native_password into the Others: text boksz. JEGYBEN KÉP!!!",
      "RCA": "Nem csatlakozott woktbench a memsql-hez. Utána elmagyaraázták",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Memsql upgrade failed",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7235",
      "Ticket Number": "#7235",
      "Title": "EOG KTYMSQLSTG31 - table compilation failure due to avx512 instruction set",
      "EOG cluster": "KTYMSQLSTG31",
      "Host": "n/a",
      "Solution": "1) SSH to node 10.4.49.31\n2) Make sure that no memsqld process is running - if so, please kill the process. (please do not kill the memsql-ops process - this process must remain running).\n3) Unmonitor the MA using memsql-ops memsql-unmonitor C3E1BB0 (if prompted if you want to remove the node from the cluster, respond NO)\n4) Navigate to the old install dir cd /var/lib/memsql/master-3306-MI1e03b494\n5) Start the MA manually using the service script: sudo ./service start --user memsql\n6) Once the MA is running, re-monitor the node memsql-ops memsql-monitor -h10.4.49.31 -uroot -p[PASSWORD]\n\n1) SSH to node ktymsqlstg35\n2) Unmonitor the MA using memsql-ops memsql-unmonitor FAA536B (if prompted if you want to remove the node from the cluster, respond NO)\n3) Navigate to the old install dir cd /var/lib/memsql/leaf-3306-MI8605dc96\n4) Start the MA manually using the service script: sudo ./service start --user memsql\n5) Once the MA is running, re-monitor the node memsql-ops memsql-monitor -hktymsqlstg35 -P3306 -uroot -p[PASSWORD]\n6) Provide output of memsql-ops memsql-list",
      "Commands": "kill -9 [pid-of-memsql-ops-here]\nls -la /var/lib/memsql/\n\nset session interpreter_mode = llvm;\nmemsql-ops memsql-update-config --all --key interpreter_mode --value llvm\nmemsql-ops memsql-update-config --all --key internal_llvm_detect_cpu_features --value false\n\n1) SSH to node ktymsqlstg35.eogresources.com\n2) Unmonitor the leaf using memsql-ops memsql-unmonitor FAA536B (if prompted if you want to remove the node from the cluster, respond NO)\n3) Confirm the leaf is no longer in the OPS list memsql-ops memsql-list\n4) Confirm the leaf is still running on the host ps aux | grep memsqld\n5) Re-monitor the leaf with the FQDN memsql-ops memsql-monitor -h ktymsqlstg35.eogresources.com -P3306 -uroot -p[PASSWORD]\n6) Provide output of memsql-ops memsql-list\n\nmemsql-ops sqlite topology.db",
      "RCA": "Memsql upgrade failed.\nTeljes memsql upgrade-et lezongoráznak a ticketben 7!!! Oldalon keresztül",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Drop user grants and passwords",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7310",
      "Ticket Number": "#7310",
      "Title": "How to get DDL back of current users",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "Command",
      "Commands": "./backup.sh -o p.sql -h node1_d -u root -pwelcome -o output \nUsing a password on the command line interface can be insecure. \nmemsql-client: [Warning] Using a password on the command line interface can be insecure. \nmemsql-client: [Warning] Using a password on the command line interface can be insecure. \n[ec2-user@ip-192-168-1-89 tools]$ cat output \nGRANT USAGE ON *.* TO 'kath'@'localhost' IDENTIFIED BY PASSWORD '*DF216F57F1F2066124E1AA5491D995C3CB57E4C2'; \nGRANT ALL PRIVILEGES ON `test`.* TO 'kath'@'localhost'; \nGRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY PASSWORD '*DF216F57F1F2066124E1AA5491D995C3CB57E4C2' WITH GRANT OPTION; \nGRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' IDENTIFIED BY PASSWORD '*DF216F57F1F2066124E1AA5491D995C3CB57E4C2' WITH GRANT OPTION;",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Backup database",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7311",
      "Ticket Number": "#7311",
      "Title": "EOG - 6 hour to restore ie_dba into env ktymsqlstg31",
      "EOG cluster": "ktymsqlstg31",
      "Host": "n/a",
      "Solution": "Never mind, mount was an autofs. Mounted show up after I ran a ls on the mount.",
      "Commands": "SELECT * FROM information_schema.MV_BACKUP_HISTORY ORDER BY Backup_Id\ncat memsql.log | grep BACKUP\nSHOW REBALANCE STATUS ON ie_dba",
      "RCA": "Sokáig futott a backup database.\nLefutott de az okát nem találták meg",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "3rd party source string + timestamp",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7365",
      "Ticket Number": "#7365",
      "Title": "EOG - Timeseries “value” column datatype",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "call",
      "Commands": "call",
      "RCA": "Calloztak, a jegyből nem derült ki semmi",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Leaf fail",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7305",
      "Ticket Number": "#7305",
      "Title": "Lost connection to a leaf while committing transactions in the cluster",
      "EOG cluster": "ktymsql26",
      "Host": 3307,
      "Solution": "Logfile check, node failed over",
      "Commands": "",
      "RCA": "Logokat kértek még visszemnőlegesen, de nem kapták meg",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Follow up",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7267",
      "Ticket Number": "#7267",
      "Title": "RE: upgrade houvlxmsqlbp01 ktyvlxmsqlbp01.eogresources.com",
      "EOG cluster": "houvlxmsqlbp01",
      "Host": "n/a",
      "Solution": "Successfully upgraded to MemSQL version 6.7.8",
      "Commands": "n/a",
      "RCA": "Follow up for #7258",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Follow up",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7263",
      "Ticket Number": "#7263",
      "Title": "RE: upgrade houvlxmsqlbp01 ktyvlxmsqlbp01.eogresources.com",
      "EOG cluster": "houvlxmsqlbp01",
      "Host": "n/a",
      "Solution": "Starting the upgrade now",
      "Commands": "n/a",
      "RCA": "Follow up for #7261",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Follow up",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7261",
      "Ticket Number": "#7261",
      "Title": "RE: upgrade houvlxmsqlbp01 ktyvlxmsqlbp01.eogresources.com",
      "EOG cluster": "houvlxmsqlbp01",
      "Host": "n/a",
      "Solution": "You can start now",
      "Commands": "n/a",
      "RCA": "Follow up for #7260",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Follow up",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7260",
      "Ticket Number": "#7260",
      "Title": "RE: upgrade houvlxmsqlbp01 ktyvlxmsqlbp01.eogresources.com",
      "EOG cluster": "houvlxmsqlbp01",
      "Host": "n/a",
      "Solution": "Where can I upgrade current prod",
      "Commands": "n/a",
      "RCA": "Follow up for #7258",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Test env. Setup",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7258",
      "Ticket Number": "#7258",
      "Title": "RE: upgrade houvlxmsqlbp01 ktyvlxmsqlbp01.eogresources.com",
      "EOG cluster": "ktyvlxmsqlbp01 / ktyvlxmsqlbp02 / ktyvlxmsqlbp03",
      "Host": "",
      "Solution": "Upgrade houvlxmslbp01 to the latest version",
      "Commands": "Test env. Setup",
      "RCA": "Test env. Setup",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "recovery failed after server brought up from bad memory",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7176",
      "Ticket Number": "#7176",
      "Title": "recovery failed after server brought up from bad memory",
      "EOG cluster": "ktymsqlstg31",
      "Host": "all hosts",
      "Solution": "It looks like a replicating database fell too far behind and reprovisioned it happens when the secondary DR cluster getting too far behind the primary cluster which has caused the secondary to give up on trying to follow along with the changes to the primary, and instead just copying a new version of the database from the primary. logs on primary were deleted too quckly for the secondary to pick up. increasing the snapshots_to_keep gives the secondary more time to catch up",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "upgrade houvlxmsqlbp01",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7243",
      "Ticket Number": "#7243",
      "Title": "upgrade houvlxmsqlbp01",
      "EOG cluster": "",
      "Host": "",
      "Solution": "ticket closed without action.",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Leaf Error (houmsql23:3306): The database 'ie_dba_79' cannot be queried until replication provisioning completes.",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7006",
      "Ticket Number": "#7006",
      "Title": "EOG - Leaf Error (houmsql23:3306): The database 'ie_dba_79' cannot be queried until replication provisioning completes.",
      "EOG cluster": "",
      "Host": "houmsql23",
      "Solution": "provisioning completes after some time increase the snapshots_to_keep, increase the snapshot_trigger_size, increase  columnstore_window_size RUN ALL THESE ON MASTER AGGREGATOR, NEEDS CLUSTER RESTART AFTER",
      "Commands": "memsql -h HOST -P PORT -u USER -pPASSWORD -e \"SHOW DATABASES EXTENDED;\" > databases_extended.sql, memsql-ops memsql-update-config --key snapshots_to_keep --value 5 --all  THIS NEEDS A FULL CLUSTER RESTARTmemsql-ops memsql-stop --all ,memsql-ops memsql-start --all memsql-ops memsql-update-config --key snapshot_trigger_size --value 2147483648 --all, memsql-ops memsql-update-config --key columnstore_window_size --value 10737418240 --all",
      "RCA": "It looks like a replicating database fell too far behind and reprovisioned it happens when the secondary DR cluster getting too far behind the primary cluster which has caused the secondary to give up on trying to follow along with the changes to the primary, and instead just copying a new version of the database from the primary. if increasing the number of snapshots is not enough try increasing the snapshot_trigger_size to 2 GB if that doesn't work either increse the columnstore_window_size",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "New Cluster install, please check settings",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7165",
      "Ticket Number": "#7165",
      "Title": "New Cluster install, please check settings",
      "EOG cluster": "",
      "Host": "",
      "Solution": "check settings",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "New Cluster install, please check settings",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7110",
      "Ticket Number": "#7110",
      "Title": "New Cluster install, please check settings",
      "EOG cluster": "",
      "Host": "",
      "Solution": "check settings",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "node remove",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7585",
      "Ticket Number": "#7585",
      "Title": "EOG - Removing a node from the cluster 2019-02-19",
      "EOG cluster": "ktymsqlb",
      "Host": "ktymsqlb03/4/5",
      "Solution": "documented steps to follow with one force delete",
      "Commands": "1. Check long running queries section of Ops web UI \n 2. Ensure all database partitions are balanced \n 3. Confirm the leaf node you want to take offline has an online paired leaf on a different host \n 4. Turn off the memsql leaf nodes you would like to delete and ensure that failover has completed (you should be able to successfully query your data—a `select count(*)` should do the trick)\n $ memsql-ops memsql-stop \n 5. Delete the memql nodes you would like to remove from the host\n $ memsql-ops memsql-delete \n 6. Uninstall memsql ops\n $ memsql-ops uninstall \n 7. Now you will no longer have anything installed on the host and you can take the host offline and perform the planned maintenance \n 8. From your primary agent host, deploy a new follower agent onto the host you just maintenanced with [AGENT-DEPLOY](https://docs.memsql.com/memsql-ops-cli-reference/v6.7/agent-deploy/). Please note, you will need to be able to `SSH` from your primary agent host into the host you are trying to deploy the memsql-ops follower agent.\n 9. Then (from any host running memsql-ops) deploy the two leaf nodes in the appropriate availability group with [MEMSQL-DEPLOY](https://docs.memsql.com/memsql-ops-cli-reference/v6.7/memsql-deploy/). Here's an example of deploying a leaf node to port 3307 in availability group 1:\n $ memsql-ops memsql-deploy -r leaf --availability-group 1 -P 3307 \n Once that final step is run and all leaf nodes are installed, the nodes should pair and rebalance automatically. To ensure your cluster is all good to go, I'd like you to send us a cluster report once you finish.\n change memo settings\n $ memsql-ops memsql-update-config --key maximum_memory --value 173437 --set-global 0F8F891 \n $ memsql-ops memsql-update-config --key maximum_memory --value 173437 --set-global 55C2C53",
      "RCA": "",
      "Comments": "https://docs.memsql.com/memsql-ops/v6.7/taking-leaves-offline-without-cluster-downtime/ If you start with fresh disks, it will probably be best to reinstall ops and the memsql nodes on the host. Once Ops and the memsql nodes are reinstalled, you can rebalance your data and the cluster will be back to normal.",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Not enough memory available to complete the current request.",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7447",
      "Ticket Number": "#7447",
      "Title": "Error: (1712, 'Leaf Error (houmsqliopt89:3307): Not enough memory available to complete the current request. The request was not processed.')",
      "EOG cluster": "houmsqliopt88",
      "Host": "houmsqliopt89:3307",
      "Solution": "n/a",
      "Commands": "to gather info:\n SELECT\n  DATABASE_NAME,\n  TABLE_NAME,\n  FLOOR(AVG(ROWS)) AS avg_rows,\n  ROUND(STDDEV(ROWS)/AVG(ROWS),3) * 100 AS row_skew,\n  FLOOR(AVG(MEMORY_USE)) AS avg_memory,\n  ROUND(STDDEV(MEMORY_USE)/AVG(MEMORY_USE),3) * 100 AS memory_skew\n FROM INFORMATION_SCHEMA.TABLE_STATISTICS\n GROUP BY 1, 2\n HAVING SUM(ROWS) > 10000\n ORDER BY row_skew DESC;\n SELECT\n  A.DATABASE_NAME,\n  A.HOST,\n  A.TABLE_NAME,\n  sum(A.ROWS) AS ROWS,\n  ROUND(sum(A.MEMORY_USE)/1024/1024,1) AS MEMORY\n FROM INFORMATION_SCHEMA.TABLE_STATISTICS A\n WHERE TABLE_NAME != 'system'\n --AND TABLE_NAME IN ('')\n GROUP BY DATABASE_NAME,TABLE_NAME, HOST\n ORDER BY DATABASE_NAME,TABLE_NAME, MEMORY;\n SELECT\n  A.DATABASE_NAME,\n  A.HOST,\n  A.PORT,\n  A.TABLE_NAME,\n  sum(A.ROWS) AS ROWS,\n  ROUND(sum(A.MEMORY_USE)/1024/1024,1) AS MEMORY\n FROM INFORMATION_SCHEMA.TABLE_STATISTICS A\n WHERE TABLE_NAME != 'system'\n GROUP BY DATABASE_NAME,TABLE_NAME, HOST, PORT\n ORDER BY DATABASE_NAME,TABLE_NAME, MEMORY;",
      "RCA": "log analysis and scripts run",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "drop and recreate database with less partitions - best way",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7445",
      "Ticket Number": "#7445",
      "Title": "need best way to drop and recreate database with less partitions.",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "If you table is not very big, you can straight with mysqldump.\n \n If your table is very big, you might think about the followings and we also provide you a end to end demo for this method too at the end:\n \n (1) create a new database with the partition number you want to have(like 128) \n (2)create those tables in this new database by using create as select\n \n ``` \n use new_db; \n create table t1 as select * from original_db.t1;\n \n ``` \n (3)Backup your new database , drop your original_db and restore new_db backup to original_db\n \n ``` \n BACKUP DATABASE new_db TO './path/' \n DROP DATABASE original_db; \n RESTORE DATABASE original_db FROM './path/new_db.backup'\n \n ```\n \n Please check out the following example for your reference by using mysqldump, it backup table \"t1\" in database \"test\":\n \n ``` \n $mysqldump test t1 -h 0 -u root -P 3306 > t1.sql \n $cat t1.sql \n -- MySQL dump 10.13 Distrib 5.5.54, for debian-linux-gnu (x86_64) \n -- \n -- Host: 0 Database: test \n -- ------------------------------------------------------ \n -- Server version 5.5.58\n \n /*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */; \n /*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */; \n /*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */; \n /*!40101 SET NAMES utf8 */; \n /*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */; \n /*!40103 SET TIME_ZONE='+00:00' */; \n /*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */; \n /*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */; \n /*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */; \n /*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;\n \n -- \n -- Table structure for table `t1` \n --\n \n DROP TABLE IF EXISTS `t1`; \n /*!40101 SET @saved_cs_client = @@character_set_client */; \n /*!40101 SET character_set_client = utf8 */; \n CREATE TABLE `t1` ( \n `DATABASE_NAME` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '', \n `TABLE_NAME` varchar(256) CHARACTER SET utf8 COLLATE utf8_bin NOT NULL DEFAULT '', \n `ORDINAL` bigint(10) DEFAULT NULL, \n `HOST` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, \n `PORT` bigint(10) DEFAULT NULL, \n `NODE_TYPE` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, \n `PARTITION_TYPE` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL, \n `ROWS` bigint(10) DEFAULT NULL, \n `MEMORY_USE` bigint(10) DEFAULT NULL \n /*!90618 , SHARD KEY () */ \n ); \n /*!40101 SET character_set_client = @saved_cs_client */;\n \n -- \n -- Dumping data for table `t1` \n --\n \n LOCK TABLES `t1` WRITE; \n /*!40000 ALTER TABLE `t1` DISABLE KEYS */; \n INSERT INTO `t1` VALUES ('test','t1',1,'10.0.2.173',3307,'Leaf','Master',0,0),('test','t1',3,'10.0.2.173',3307,'Leaf','Master',0,0),('test','t1',4,'10.0.2.173',3307,'Leaf','Master',0,0),('test','t1',7,'10.0.2.173',3307,'Leaf','Master',0,0),('test','t1',2,'10.0.2.173',3307,'Leaf','Master',0,0),('test','t1',6,'10.0.2.173',3307,'Leaf','Master',0,0),('test','t1',0,'10.0.2.173',3307,'Leaf','Master',0,0),('test','t1',5,'10.0.2.173',3307,'Leaf','Master',0,0); \n /*!40000 ALTER TABLE `t1` ENABLE KEYS */; \n UNLOCK TABLES; \n /*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;\n \n /*!40101 SET SQL_MODE=@OLD_SQL_MODE */; \n /*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */; \n /*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */; \n /*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */; \n /*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */; \n /*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */; \n /*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;\n \n -- Dump completed on 2019-01-31 22:08:21\n \n ```\n \n The following is one example to use the second method:\n \n ``` \n memsql> create database test partitions 4; \n Query OK, 1 row affected (2.79 sec)\n \n memsql> use test; \n Database changed \n memsql> show partitions; \n +---------+------------+------+--------+--------+ \n | Ordinal | Host | Port | Role | Locked | \n +---------+------------+------+--------+--------+ \n | 0 | 10.0.2.173 | 3307 | Master | 0 | \n | 1 | 10.0.2.59 | 3307 | Master | 0 | \n | 2 | 10.0.2.173 | 3307 | Master | 0 | \n | 3 | 10.0.2.59 | 3307 | Master | 0 | \n | 0 | 10.0.2.59 | 3307 | Slave | 0 | \n | 1 | 10.0.2.173 | 3307 | Slave | 0 | \n | 2 | 10.0.2.59 | 3307 | Slave | 0 | \n | 3 | 10.0.2.173 | 3307 | Slave | 0 | \n +---------+------------+------+--------+--------+ \n 8 rows in set (0.00 sec)\n \n memsql> show tables; \n Empty set (0.00 sec)\n \n memsql> create table t1 as select * from information_schema.table_statistics; \n Query OK, 8 rows affected (0.35 sec)\n \n memsql> create database test_new partitions 2; \n Query OK, 1 row affected (2.29 sec)\n \n memsql> use test_new; \n Database changed \n memsql> create table t1 as select * from test.t1; \n Query OK, 8 rows affected (0.86 sec)\n \n memsql> select count(1) from test.t1; \n +----------+ \n | count(1) | \n +----------+ \n | 8 | \n +----------+ \n 1 row in set (0.20 sec)\n \n memsql> select count(1) from test_new.t1; \n +----------+ \n | count(1) | \n +----------+ \n | 8 | \n +----------+ \n 1 row in set (0.20 sec)\n \n memsql> use test_new; \n Database changed \n memsql> show partitions; \n +---------+------------+------+--------+--------+ \n | Ordinal | Host | Port | Role | Locked | \n +---------+------------+------+--------+--------+ \n | 0 | 10.0.2.173 | 3307 | Master | 0 | \n | 1 | 10.0.2.59 | 3307 | Master | 0 | \n | 0 | 10.0.2.59 | 3307 | Slave | 0 | \n | 1 | 10.0.2.173 | 3307 | Slave | 0 | \n +---------+------------+------+--------+--------+ \n 4 rows in set (0.00 sec)\n \n memsql> backup database test_new to '/tmp/'; \n +-----------+----------------+----------------------+---------------+---------------------+---------------------+----------------+----------------------+--------------------------+---------+------+ \n | Backup_Id | Cluster_Name | Cluster_Id | Database_Name | Start_Timestamp | End_Timestamp | Num_Partitions | Backup_Path | Checksum | Status | Size | \n +-----------+----------------+----------------------+---------------+---------------------+---------------------+----------------+----------------------+--------------------------+---------+------+ \n | 1 | memsql_cluster | 10949535620706328755 | test_new | 2019-01-31 23:38:11 | 2019-01-31 23:38:12 | 2 | /tmp/test_new.backup | 54826dc49b53cff8c31696d1 | Success | 5815 | \n +-----------+----------------+----------------------+---------------+---------------------+---------------------+----------------+----------------------+--------------------------+---------+------+ \n 1 row in set (0.12 sec)\n \n memsql> drop database test; \n Query OK, 1 row affected (1.52 sec)\n \n memsql> restore database test from '/tmp/test_new.backup'; \n Query OK, 1 row affected (3.12 sec)\n \n memsql> use test; \n Reading table information for completion of table and column names \n You can turn off this feature to get a quicker startup with -A\n \n Database changed \n memsql> show partitions; \n +---------+------------+------+--------+--------+ \n | Ordinal | Host | Port | Role | Locked | \n +---------+------------+------+--------+--------+ \n | 0 | 10.0.2.173 | 3307 | Master | 0 | \n | 1 | 10.0.2.59 | 3307 | Master | 0 | \n | 0 | 10.0.2.59 | 3307 | Slave | 0 | \n | 1 | 10.0.2.173 | 3307 | Slave | 0 | \n +---------+------------+------+--------+--------+ \n 4 rows in set (0.00 sec)\n \n memsql> select count(1) from t1; \n +----------+ \n | count(1) | \n +----------+ \n | 8 | \n +----------+ \n 1 row in set (0.12 sec)\n \n memsql>\n \n ```\n \n Please be sure to test above methods in your test environment before you proceed.",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "CREATE DATABASE requires that all availability groups are balanced.",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7376",
      "Ticket Number": "#7376",
      "Title": "ERROR 1782 (HY000): CREATE DATABASE requires that all availability groups are balanced. The largest group has 16 leaves, while the smallest has 0. The",
      "EOG cluster": "",
      "Host": "",
      "Solution": "change the redundancy level back to 1 and then use the ops command to enable high availability which will configure things automatically",
      "Commands": "on master aggregator SHOW LEAVES;\n memsql> SET @@GLOBAL.redundancy_level = 1;\n memsql> Select @@GLOBAL.redundancy_level;\n memsql> exit\n $ memsql-ops memsql-enable-high-availability",
      "RCA": "Probably caused by:Half of your leaves are not online, all of which belong to the same availability group (and that you have 32 total leaves).\n A recent change was made regarding High Availablity.\n What most likely happened was the redundancy level 2 was enabled after adding all the leaves.",
      "Comments": "https://docs.memsql.com/operational-manual/v6.7/managing-high-availability/\n https://docs.memsql.com/sql-reference/v6.7/add-leaf/\n Otherwise, you can disable redundancy_level = 2 and use the memsql-ops memsql-enable-high-availability command to have memsql-ops automatically set up the node pairings for you.\n https://docs.memsql.com/memsql-ops-cli-reference/v6.7/memsql-enable-high-availability/\n https://docs.memsql.com/ops-redir/disabling-high-availability",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "reduce storage on /var/lib/memsql",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7470",
      "Ticket Number": "#7470",
      "Title": "Need to reduce storage on /var/lib/memsql without bouncing the cluster",
      "EOG cluster": "ktymsql30",
      "Host": "",
      "Solution": "memsql-ops memsql-update-config --key columnstore_window_size --value 4294967296 --set-global –all",
      "Commands": "memsql> show variables like '%snaps%';\n du -h for check usage in /var/lib/memsql",
      "RCA": "clusterman output showed high usage\n [SYS] Disk Space Usage Critical: \n ktymsql28: 94% Disk Space Usage \n --\n after du -h possible scenarios:\n Please inform us of where the large amount of data is getting stored.\n  For example if it is in the plancache, then we can look into your query plan rotation strategy. \n If it is instead in backups that were stored locally on the leaves, they could be moved elsewhere (eg to an NFS). \n If it is in the snapshots and transaction logs, we could evaluate the snapshots to keep against avoiding reprovisioning.\n old logs,memsql-ops.log,core files can be deleted older than one month old",
      "Comments": "OPS needs at least 50 MB of disk in order to run",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Ops follower agent crashing",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7330",
      "Ticket Number": "#7330",
      "Title": "EOG - Ops follower agent crashing on ktymsqlb06",
      "EOG cluster": "ktymsqlb01",
      "Host": "ktymsqlb06",
      "Solution": "ensure memsql-ops starts upon server startup and to make this change across all of your hosts.",
      "Commands": "from ops config file:\n find . -name settings.conf | xargs grep started_as_root\n started_as_root = False\n To check if its enabled, run: systemctl status memsql-ops. \n To set, run: systemctl enable memsql-ops\n This method only works if you are using systemD startup manager and have systemctl.\n \n after node stopped from master aggregator run these:\n SHOW AGGREGATORS and SHOW LEAVES\n memsql-ops memsql-list\n memsql-ops agent-list\n to get detailed infos\n memsql-ops report --tracelog-mb 500 --include-log-archives\n to check host uptimes:\n Output of last -x reboot from ktymsqlb06\n /var/log/messages file from ktymsqlb06",
      "RCA": "after restart it stays in offline\n memsql-ops agent-start and at least 50 MB space on disk was asked for\n after restart report is demanded memsql-ops report\n ops was not installed with sudo/root\n if it is not possibel ask for share mesql-ops.log from its local drive\n on other ticetk frequent rebott was reported, might cause this , that machine repair was suggested, its repair info was asked also\n ops was installed without sudo/root\n ops resatrt info was searched - was it intendly or for other reason",
      "Comments": "#7274 - this cluster rebooted frquently so this would describe the root cause of offlineness\n https://docs.memsql.com/memsql-ops/v6.7/full-installation-guide/#installing-without-sudo-access\n  if you are using systemD startup manager and have systemctl, then it will start memsql-ops automatically:\n To check if its enabled, run: systemctl status memsql-ops. \n To set, run: systemctl enable memsql-ops",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "MemSQL ticket access",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7254",
      "Ticket Number": "#7254",
      "Title": "Add me to EOG",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "user added to EOG resources memsql support team",
      "Commands": "",
      "RCA": "n/a",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Delayed refresh between clusters (PRD-STG)",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7315",
      "Ticket Number": "#7315",
      "Title": "RE: Delayed ie_dba refresh on ktymsqlstg31",
      "EOG cluster": "KTYMSQL30",
      "Host": "n/a",
      "Solution": "finished process finally",
      "Commands": "n/a",
      "RCA": "n/a",
      "Comments": "this is a follow-up of7312, that is finished",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Delayed refresh between clusters (PRD-STG)",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7313",
      "Ticket Number": "#7313",
      "Title": "Re: Delayed ie_dba refresh on ktymsqlstg31",
      "EOG cluster": "KTYMSQL30",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "n/a",
      "RCA": "n/a",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Delayed refresh between clusters (PRD-STG)",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7312",
      "Ticket Number": "#7312",
      "Title": "Delayed ie_dba refresh on ktymsqlstg31",
      "EOG cluster": "KTYMSQL30",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "n/a",
      "RCA": "Refresh of ie_dba from prod KTYMSQL30 to stage ktymsqlstg31 is being delayed",
      "Comments": "This is a follow-up to your previous request #7312 \"Delayed ie_dba refresh on k...\"\n Refresh of ie_dba from prod KTYMSQL30 to stage ktymsqlstg31 is being delayed , I am checking with memsql support why is it taking so much time as compared to usual 3 hrs. time length, refresh was started around noon and still going on. I will inform as soon as it finishes.",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "NFS share for memsqlbackup",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7314",
      "Ticket Number": "#7314",
      "Title": "RE: NFS share for memsqlbackup",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "memsql> RESTORE ie_dba FROM \"/memsqlbackup/iedba_01192019TP\";",
      "RCA": "",
      "Comments": "Herman,\n \n Restore just finished\n memsql> RESTORE ie_dba FROM \"/memsqlbackup/iedba_01192019TP\";\n Query OK, 1 row affected (6 hours 2 min 0.06 sec)\n I think you should have logged in earlier :P Please check later if it was related to mount point or network.\n \n From: Herman Leung \n Sent: Saturday, January 19, 2019 7:03 PM \n To: Tanvi Parekh <Tanvi_Parekh@eogresources.com>; Shabbir Gandhi <Shabbir_Gandhi@eogresources.com> \n Subject: NFS share for memsqlbackup\n \n Just logged on to the system, I don’t see any issues on the NAS\n houcmpnas01.eogresources.com is the target\n Herman",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "High memory usage and slow queries",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7098",
      "Ticket Number": "#7098",
      "Title": "EOG PRD - PROD running slow",
      "EOG cluster": "KTYMSQL30",
      "Host": "n/a",
      "Solution": "killing all the running queries",
      "Commands": "Collect activities\n memsql -h HOST -P PORT -u USER -pPASSWORD -e \"set activities_delta_sleep_s = 20; select mvae.*, query_text from information_schema.mv_activities_extended mvae left join information_schema.mv_queries mvq on mvae.activity_name = mvq.activity_name\" | gzip > activities.tsv.gz\n Collect nodes\n memsql -h HOST -P PORT -u USER -pPASSWORD -e \"select * from information_schema.mv_nodes\" | gzip > nodes.tsv.gz",
      "RCA": "queries or query specification asked for, not mentioned in ticket what is slow\n query load consumed high memo\n Resource Governance was advised to investiagte anomalies\n This allows you to assign resource pools to different users, and limit the percent of memory and runtime of queries that they are permitted to use. \n In version 6.7 we also added the ability to limit users' CPU usage, and concurrency.",
      "Comments": "https://docs.memsql.com/operational-manual/v6.7/setting-resource-limits/",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "MemsSQL upgrade fail",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7085",
      "Ticket Number": "#7085",
      "Title": "EOG PRD- upgrade failed, need help in proceeding further",
      "EOG cluster": "ktymsqlfin11",
      "Host": "n/a",
      "Solution": "1) memsql-ops memsql-stop --all\n 2) Upgrade with the --skip-version-check flag\n memsql-ops memsql-upgrade --version 6.7.4 --skip-version-check\n memsql-ops memsql-upgrade --version 6.7.4 --skip-version-check --skip-snapshot , because db is offline",
      "Commands": "memsql-ops file-add /path/to/binary",
      "RCA": "leaf - unable to upgrade - node port lockdown was asked for \n manual binary add advised\n To verify, you could try pinging download.memsql.com from the master and ktymsqlfin14:3307 to see if it can establish a connection in order to investigate possibel network RC \n Memsql OPS team answer:\"they believe that this was likely a blip on this AWS hosted download server.",
      "Comments": "https://docs.memsql.com/memsql-ops-cli-reference/v6.7/file-add/ similar case was #7067.",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Not enough memory available to complete the current request",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7062",
      "Ticket Number": "#7062",
      "Title": "EOG PRD - Not enough memory available to complete the current request on WED 2018-12-06",
      "EOG cluster": "KTYMSQL30",
      "Host": "ktymsql24:3308",
      "Solution": "The query sent earlier is sorting for the window functions. To make this query use less memory change the sort key to match the window function.",
      "Commands": "memsql> SELECT\n  -> DATABASE_NAME,\n  -> TABLE_NAME,\n  -> FLOOR(AVG(ROWS)) AS avg_rows,\n  -> ROUND(STDDEV(ROWS)/AVG(ROWS),3) * 100 AS row_skew,\n  -> FLOOR(AVG(MEMORY_USE)) AS avg_memory,\n  -> ROUND(STDDEV(MEMORY_USE)/AVG(MEMORY_USE),3) * 100 AS memory_skew\n  -> FROM INFORMATION_SCHEMA.TABLE_STATISTICS\n  -> GROUP BY 1, 2\n  -> HAVING SUM(ROWS) > 10000\n  -> ORDER BY row_skew DESC;\n PROFILE select_query;\n PROFILE select_query;\n SHOW PROFILE;\n memsql-ops report --tracelog-mb 1000",
      "RCA": "queries and their profile asked for investigation\n no evidence found,",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Requesting License file",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7099",
      "Ticket Number": "#7099",
      "Title": "Requesting License file",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "license link provided",
      "Commands": "environmental check:select @@memsql_version",
      "RCA": "",
      "Comments": "binary provided to eog to install memsql\n https://docs.memsql.com/operational-manual/v6.7/replacing-a-memsql-license/",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Leaf error OOM",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7063",
      "Ticket Number": "#7063",
      "Title": "Error: (1712, 'Leaf Error (ktyvlxmsqlio03:3306): Not enough memory available to complete the current request. The request was not processed.')",
      "EOG cluster": "ktyvlxmsqlio03",
      "Host": 3306,
      "Solution": "After the Commands memsql-ops memsql-restart --all",
      "Commands": "memsql-ops report --tracelog-mb 1000\n memsql-ops memsql-list -q -r leaf | xargs -L 1 memsql-ops memsql-update-config --key maximum_table_memory --value 26177 --set-global\n memsql-ops memsql-list -q -r leaf | xargs -L 1 memsql-ops memsql-update-config --key maximum_memory --value 29086 --set-global",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Pipleine not working",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7035",
      "Ticket Number": "#7035",
      "Title": "[memsql.com] Pipeline arent working",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "select * from information_schema.pipelines_errors;\n select * from information_schema.PIPELINES;\n select * from information_schema.PIPELINES_BATCHES;",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "memsql Upgrade failed",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7017",
      "Ticket Number": "#7017",
      "Title": "Memsql agent upgrade failed from version 6.0.11 to version 6.7.1",
      "EOG cluster": "opsmsqldev",
      "Host": "n/a",
      "Solution": "Permission issues, run with sudo",
      "Commands": "memsql-ops agent-start, memsql-ops start, memsql-ops _upgrade --version 6.7.1",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "memsql Upgrade failed",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7067",
      "Ticket Number": "#7067",
      "Title": "Memsql Upgrade",
      "EOG cluster": "ktymsqla",
      "Host": "ktymsqla03 / ktymsqla02",
      "Solution": "Commands",
      "Commands": "memsql-ops agent-upgrade --file-path /path/to/memsql-ops-6.7.1.tar.gz\n memsql-ops memsql-upgrade --file-path /path/to/memsqlbin_amd64.tar.gz --skip-version-check\n memsql-ops license-add --license-key LICENSE_KEY --license-file LICENSE_FILE",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Leaf error can't open file",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7020",
      "Ticket Number": "#7020",
      "Title": "Error Code: 1016. Leaf Error (houmsqlfin16:3309): Can't open file: 'columns/LPC_ADM_16/7/3447/50447' (errno: 2)",
      "EOG cluster": "houmsqlfin15 / houmsqlfin16",
      "Host": "3309, 3308",
      "Solution": "Solution was dropping and reloading the tables",
      "Commands": "memsql -h HOST -P PORT -u USER -pPASSWORD -e \"SHOW CLUSTER STATUS;\" > cluster_status.txt\n memsql -h HOST -P PORT -u USER -pPASSWORD -e \"SHOW DATABASES EXTENDED;\" > databases_extended.txt\n On houmsqlfin16:3309 run:\n _REPAIR_TABLE LPC_ADM_16.table_name;\n \n On houmsqlfin15:3308 run:\n _REPAIR_TABLE LPC_ADM_45.table_name;",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "LEAF status RECOVERY_FAILED",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7007",
      "Ticket Number": "#7007",
      "Title": "LEAF status RECOVERY_FAILED",
      "EOG cluster": "",
      "Host": "",
      "Solution": "SNAPSHOT LPC_ADM from the master aggregator: Drop the slave partition Run the rebalance again Also issue is fixed in version 6.7",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "PRD - RECOVERY_FAILED status IOPT",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6996",
      "Ticket Number": "#6996",
      "Title": "PRD - RECOVERY_FAILED status IOPT",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Update the clusters to the same version",
      "Commands": "",
      "RCA": "Server version mismatch caused the issue.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "stage: packet wait, state: x_streaming, err: no",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7016",
      "Ticket Number": "#7016",
      "Title": "stage: packet wait, state: x_streaming, err: no",
      "EOG cluster": "ktyvlxmsqlcdm01",
      "Host": "ktyvlxmsqlcdm03",
      "Solution": "ticket closed without action.",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "EOG STG - rebalance partitions",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6999",
      "Ticket Number": "#6999",
      "Title": "EOG STG - rebalance partitions",
      "EOG cluster": "",
      "Host": "",
      "Solution": "#7007",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Error\t1728\tFailed to synchronize database. Timed out waiting for slave to synchronize",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6964",
      "Ticket Number": "#6964",
      "Title": "Error 1728 Failed to synchronize database. Timed out waiting for slave to synchronize",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Restart the node, if query lock prevents it, kill the query",
      "Commands": "memsql-ops memsql-stop, memsql-ops memsql-start",
      "RCA": "Alter table got stuck, this issue was fixed by MEMAQL later, it should not happen again",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Queried table cannot deleted",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7055",
      "Ticket Number": "#7055",
      "Title": "Re: EOG - Unkillable DROP commands while long running query present in cluster",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "long running query kill",
      "Commands": "KILL CONNECTION 74706;\n Long running query was this:\n SELECT * FROM (SELECT *\\n FROM LPC_ADM.DDETAIL\\n WHERE (USDAMT != 0 OR VOL != 0 OR LCAMT != 0 OR LOCVOL != 0)\\n AND DDETAIL.GEN != 830\\n -- AND acctyr = 2018 AND acctmo = 1\\n -- AND CCNUM = IS NULL(TO_CHAR (PRPRTY(+), 'FM000000'), '') + IS NULL(PRPSUB(+), '')\\n AND NOT EXISTS\\n (SELECT 'x'\\n FROM LPC_ADM.LP_CC_MATCH_NOCO\\n WHERE CC_NUM = CCNUM)\\n AND SRCSYS IN ('P', 'H')) DDETAIL\\n LEFT OUTER JOIN\\n (SELECT PRPRTY,\\n PRPSUB,\\n CC_NUM,\\n CASE WHEN UPDATE_BY IS NULL THEN W.DIVIS ELSE X.UPDATE_BY END\\n DIVIS,\\n OPRCO,\\n WLOPR\\n FROM LPC_ADM.WLDDPF_LPC W\\n LEFT OUTER JOIN LPC_ADM.DM_CODES X\\n ON X.CODE = 'DDIVXREF' AND W.DIVIS = X.CODE_DESC) S\\n ON DDETAIL.CCNUM = S.CC_NUM AND CO = OPRCO\\n JOIN LPC_ADM.LP_REPORT_TREE_GENSUB B\\n ON DDETAIL.GEN = B.GEN AND DDETAIL.SUB = B.SUB\\nGROUP BY ACCTYR,\\n ACCTMO,\\n SRVYRW,\\n SRVMONW,\\n DIVWRK,\\n CO,\\n CCNUM,\\n SRCSYS,\\n LCCUR,\\n GRSNETFL,\\n DDETAIL.GEN,\\n DDETAIL.SUB,\\n MAJOR,\\n MINOR,\\n JENUM,\\n RLUPCD1,\\n DECK,\\n DDETAIL.BUSNASSC,\\n DDETAIL.AFE,\\n DIVIS,\\n DDETAIL.DIV\\nLIMIT 0, 1000",
      "RCA": "A table cannot be dropped which currently has a query executing against the table.\n long running select query detected, killed as per its PID\n this long running query was not showed in UI\n drop table was asked for to update in order to drop queried tables also or drop table force was suggested",
      "Comments": "follow-up to your previous request #6899",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Assistance asking during upgrade",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6980",
      "Ticket Number": "#6980",
      "Title": "EOG - PRD upgrade to 6.7.1 - need support for upgrade today.",
      "EOG cluster": "ktymsql30",
      "Host": "n/a",
      "Solution": "memsql backup directory permission change for memsql user from root",
      "Commands": "memsql-ops agent-upgrade\n for check backup folder content: /path/to/memsql-ops/memsql_backups` and `cd` into `memsql_backups` and run `df -h`.\n check for folders/permissions\n [memsql@ktymsql30 data]$ cd /var/lib/memsql-ops/data/ \n [memsql@ktymsql30 data]$ ls \n [memsql@ktymsql30 data]$ ls -ltr \n [memsql@ktymsql30 data]$ df -kh \n memsql access check to `/memsql_backups`?\n ls -l /memsql_backups\n to get riport for longer time:\n memsql-ops report --include-log-archives --tracelog-mb 500\n SHOW WARNINGS after upgrade to collect replication db's warn message\n SHOW REPLICATION STATUS ON is_dba\n SHOW CLUSTER STATUS for check any affected by warnings\n memsql-ops status to check version on leafs\n dmesg -T was asked for offline agents root cause investigate",
      "RCA": "during upgrade agents have invalid SSH credentials to hosts\n on a leaf memsql user did not have the right permission to read/write /var/lib/memsql-ops/data/memsql_backups\n memsql_backups directory had root privileges\n prior upgrade ops agent list should have been checked with memsql-ops agent-list",
      "Comments": "Plan as below (please confirm) :\n \n Stop the workload. \n Upgrade OPS on the secondary (read-only) cluster. \n Upgrade the secondary (read-only) cluster. \n Upgrade OPS on the primary (read/write) cluster. \n Upgrade the primary (read/write) cluster. \n Drop any replicated databases from the secondary cluster DROP DATABASE database_name \n Start replication again on the secondary cluster REPLICATE DATABASE db_name FROM master_user[:'master_password']@master_host[:master_port][/master_db_name] \n Start the workload.\n memsql-upgrade --version 7.6.3 come out in that time so version flag needed to set\n there is one fix for EOG in this release relating to ticket #6884 where a during DR replication, a slave might get behind a master and report that it is missing a columnar blob file.\n feature requested to store warning messages in a separate table!!!",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Pipeline not working",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/7036",
      "Ticket Number": "#7036",
      "Title": "[memsql.com] pipelines arent working",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "n/a",
      "RCA": "n/a",
      "Comments": "merged into #7035",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Cluster upgrade version set in command",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6967",
      "Ticket Number": "#6967",
      "Title": "EOG STG - planning for upgrade",
      "EOG cluster": "ktymsqlstg31",
      "Host": "n/a",
      "Solution": "rebalance partition before memsql-upgrade with version flag - by default it is matching with ops version not to the latest",
      "Commands": "EXPLAIN REBALANCE PARTITIONS on ie_dba;\n REBALANCE PARTITIONS ON ie_dba;\n memsql-ops memsql-upgrade --stop-timeout 6000",
      "RCA": "EXPLAIN REBALANCE PARTITIONS shows first copy partition force then promote partition with drop , this output is normal\n memsql-ops should upgrade first to follow memsql db to upgrade as well to later version but this is not mandatory - only recommended (..haha) so version flag can be used",
      "Comments": "https://docs.memsql.com/sql-reference/v6.0/rebalance-partitions/",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Leaf Error : Can't open file:",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6787",
      "Ticket Number": "#6787",
      "Title": "EOG - Error Code: 1016. Leaf Error (houmsql18:3309): Can't open file: 'columns/ie_dba_42/1/7241241/643942443' (errno: 2)",
      "EOG cluster": "n/a",
      "Host": "houmsql18:3309/ktymsql24:3308",
      "Solution": "Restarting secondary cluster houmsql fixed the problem\n bug fix was released based on this",
      "Commands": "",
      "RCA": "memsql.log and report examination to provide postmortem\n master aggregator was not online when any leaves were stopped so we can rule out improper start as a root cause of the trigger.\n we can rule out the master aggregator being started while leaves were online as a root cause.\n The bug which caused the incident on 2018-10-17 has been successfully identified and reproduced by the dev team.",
      "Comments": "Bug Summary\n There are some cases where after cluster restart a columnar blob file gets deleted when it should not be deleted on slave databases (in this case the secondary cluster). Note: the issue began after the secondary cluster was restarted earlier in the day on 2018-10-17.\n \n Bug Details\n When recovery is done, there is a process that scans the disk, and marks any columnar blobs on disk, but not in metadata for deletion, in order to avoid leaking blobs (this function is called CleanupSegmentFiles).\n It is possible, however, for recovery of a slave database to finish in the middle of a transaction, for example if a blob in the middle of the transaction is missing because it was never sent by the master database.\n When that happens, the transaction is left open, in an uncommitted state, so CleanupSegmentFiles will delete any blobs tracked by that transaction.\n The blobs that get deleted unforunately have already been verified as being on disk, that's why a restart was needed to redownload them (recall how restarting the secondary cluster fixed the issue).\n The issue may not be immediately triggered because the deletes happen via the columnstore window. This is why the issue began happening some time after the secodary cluster restart on 2018-10-17.",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Array issue in stored procedure",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6926",
      "Ticket Number": "#6926",
      "Title": "EOG - Issues with Arrays in Stored Procedures",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "overwrite of procedure: delimited string hass to be passed to the stored procedure\n and use sp function to return array from delimited text",
      "Commands": "suggested function :\n ``` \n delimiter // \n create or replace function split_string(input text, d text) returns array(text) as \n declare \n result array(text) = []; \n position int = 1; \n newPosition int = -1; \n begin \n while newPosition != 0 loop \n newPosition = locate(d, input, position); \n if newPosition != 0 then \n result += [substring(input, position, newPosition - position)]; \n position = newPosition + 1; \n end if; \n end loop;\n \n -- Add the last delimited element \n result += [substring_index(input, d, -1)]; \n return result; \n end // \n delimiter ; \n ```",
      "RCA": "stored procedure submission asked and analysed",
      "Comments": "https://docs.memsql.com/concepts/v6.5/code-generation/",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Query slow on columnarstore table",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6797",
      "Ticket Number": "#6797",
      "Title": "Query Execution Time on ColumnarStore Table Increasing",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "n/a",
      "RCA": "n/a",
      "Comments": "only the dml and ddl script provided without any comment/feedback, requestor asked for mobile call\n one picture about exec time of the query was also attached where last hours showed less second than its constant slight increase in previous hours, dropped from 4 to 1 sec!!\n ticket was raised as query performance decrease, although its increase it might be fallen down its original exec time",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Replication error",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6696",
      "Ticket Number": "#6696",
      "Title": "STG-Replication error",
      "EOG cluster": "houmsqliopt88",
      "Host": "n/a",
      "Solution": "replication not executed because of technical unsimilarities, version mismatch with memo size difference also\n but licence should have been added to memsql also in order to execute",
      "Commands": "usage: memsql-ops license-add [--settings-file SETTINGS_FILE] [--async](--license-key LICENSE_KEY | --license-file LICENSE_FILE)\n To find out which tables are causing the skew, please run this query and send us out the output:\n \n SELECT\n  DATABASE_NAME,\n  TABLE_NAME,\n  FLOOR(AVG(ROWS)) AS avg_rows,\n  ROUND(STDDEV(ROWS)/AVG(ROWS),3) * 100 AS row_skew,\n  FLOOR(AVG(MEMORY_USE)) AS avg_memory,\n  ROUND(STDDEV(MEMORY_USE)/AVG(MEMORY_USE),3) * 100 AS memory_skew\n FROM INFORMATION_SCHEMA.TABLE_STATISTICS\n GROUP BY 1, 2\n HAVING SUM(ROWS) > 10000\n ORDER BY row_skew DESC;",
      "RCA": "developer memsql version run on cluster\n licence key activation advised to use all feature, including replication\n houmsqliopt88 -> ktyvlxmsqlio01, both leafs should have same partition to not run into possible memo issue\n plus ops/db version shoudl also match\n Data skew detected on cluster:\"The smallest leaf has 18981 MB of table data while the largest has 48074 MB. That is 250% data skew. This can cause unwanted performance problems and we want to make sure data is equally distributed across all partitions and nodes.",
      "Comments": "https://docs.memsql.com/introduction/latest/memsql-faq/ https://docs.memsql.com/memsql-ops-cli-reference/v6.5/license-add/ https://docs.memsql.com/operational-manual/v6.5/using-replication/",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Not enough memory available to complete the current request",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6686",
      "Ticket Number": "#6686",
      "Title": "EOG STG - KTYMSQLSTG31 - table iot_dba.iot skewed",
      "EOG cluster": "ktymsqlstg31",
      "Host": "ktymsqlstg36",
      "Solution": "rewrite of query:\n replacing (tag_ts-(tag_ts % 1)) with tag_ts from the group by\n with other rewrite query as second option",
      "Commands": "PROFILE select\n  * \n  from...;\n show profile;",
      "RCA": "query casued peak memo usage, its profile report was asked\n query used hashgroupby - optimization was suggested to lower memo consumption\n data skew was detected on one leaf and other shard key recommended",
      "Comments": "https://docs.memsql.com/concepts/v6.5/data-skew/\n https://docs.memsql.com/tutorials/v6.5/optimizing-table-data-structures/#shard-keys",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Issue with Arrays in Stored Procedure",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6925",
      "Ticket Number": "#6925",
      "Title": "Issue with Arrays in Stored Procedure",
      "EOG cluster": "",
      "Host": "",
      "Solution": "ticket closed without action.",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Query Execution Time on ColumnarStore Table Increasing",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6798",
      "Ticket Number": "#6798",
      "Title": "Query Execution Time on ColumnarStore Table Increasing",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Developers rewrote the query",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "EOG PROD- running very slow and timeout message",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6766",
      "Ticket Number": "#6766",
      "Title": "EOG PROD- running very slow and timeout message",
      "EOG cluster": "ktymsql30",
      "Host": "",
      "Solution": "Clean plancashe",
      "Commands": "run on MA memsql-ops memsql-update-config --key sampling_estimates_for_complex_filters --value on --set-global --all, memsql-ops memsql-update-config --key plan_expiration_minutes --value 0 --set-global --all, memsql-ops memsql-update-config --key plan_expiration_minutes --value 720 --set-global --all",
      "RCA": "sampling_estimates_for_complex_filters was disabled increasing time",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "ITypeCurve STG - no master error",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6758",
      "Ticket Number": "#6758",
      "Title": "ITypeCurve STG - no master error",
      "EOG cluster": "ktymsqlstg31",
      "Host": "ktymsqlstg40",
      "Solution": "Restart leafs",
      "Commands": "",
      "RCA": "Leafs were down",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Auto Increment not working for a properly created table",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6290",
      "Ticket Number": "#6290",
      "Title": "Auto Increment not working for a properly created table",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Mysql workbench caused the issue.",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Query bug",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6672",
      "Ticket Number": "#6672",
      "Title": "Bug with Query Processing",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "query rewrite",
      "Commands": "n/a",
      "RCA": "script format change advised : \"wrapping the table and fulltext function in the project list of a subselect.\"\n internal bugfix/feature was opened for align with original script to work",
      "Comments": "https://docs.memsql.com/concepts/v6.5/full-text-search/\n https://docs.memsql.com/sql-reference/v6.5/match/",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Upgrade assistance request",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6529",
      "Ticket Number": "#6529",
      "Title": "MemSQL iTypeCurve Production Upgrade - 6.0.23 to 6.5.12",
      "EOG cluster": "ktymsql30",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "Commands output to review:\n 1. SHOW LEAVES; \n 2. SHOW AGGREGATORS; \n 3. SHOW CLUSTER STATUS; \n 4. memsql -v -u root -p<passwd> -e \"show cluster status\" |egrep -i 'orphan|pending' |wc -l \n 5. EXPLAIN RESTORE REDUNDANCY; \n 6. EXPLAIN REBALANCE PARTITIONS; \n 7. SELECT count(1) from information_schema.distributed_partitions where Role = 'Orphan'; \n 8. memsql-ops memsql-list --include-unmonitored\n \n memsql-ops memsql-start should be triggered on master aggregator\n \n db on clsuter has:\n GRANT PROCESS, FILE READ, SHOW METADATA ON *.* TO 'ie_dba'@'%' IDENTIFIED BY PASSWORD '*'\n GRANT ALL PRIVILEGES ON `ie_dba`.* TO 'ie_dba'@'%' WITH GRANT OPTION\n \n check connection from load balancer hint:\n mysql -h10.4.55.30 -P3306 -uie_dba -p -e \"select 1\";",
      "RCA": "steps Suggested to upgrade\n \n Stop the workload. \n Upgrade OPS on the secondary (read-only) cluster. \n Upgrade the secondary (read-only) cluster. \n Upgrade OPS on the primary (read/write) cluster. \n Upgrade the primary (read/write) cluster. \n Drop any replicated databases from the secondary cluster DROP DATABASE database_name \n Start replication again on the secondary cluster REPLICATE DATABASE db_name FROM master_user[:'master_password']@master_host[:master_port][/master_db_name] \n Start the workload.\n \n Agents were offline so this action needed to take:\n for the agents you will need to SSH into each host and run memsql-ops _upgrade --version 6.5.8 (this assumes these machines are not behind firewall)\n later version included fix that appeared in this upgrade : MA & CA crashed\n EOG upgraded only to 6.5.8, although in ticket title.12 appears\n upgrade might fail because app team connecting masters via Load Balancer, permissions are checked on aggregators\n \n not the PRD cluster was affected during , that node full details ips etc was asked for further investigation",
      "Comments": "#5644 was prior upgrade\n https://docs.memsql.com/operational-manual/v6.0/upgrading-to-60/#step-1-verify-your-cluster-is-ready-for-upgrade\n https://docs.memsql.com/troubleshooting/latest/troubleshooting-overview/",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Insert a CHAR into a INT succeeds and inserts 0",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6199",
      "Ticket Number": "#6199",
      "Title": "Insert a CHAR into a INT succeeds and inserts 0 ???",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "set global data_conversion_compatibility_level = 6.5",
      "RCA": "Currently MemSQL does not throw errors on integer and string type conversions, to match MySQL in non-strict mode. \n configure data_conversion_compatibility_level to error in this case.\n feature request might be raised for\n ```CREATE TABLE `BP_MODULE` ( \n MODULE_ID int(11) DEFAULT NULL, \n MODULE_DESC int(11) DEFAULT NULL, \n CREATED_BY VARCHAR(20) not null , \n UPDATE_BY VARCHAR(20) not null , \n `CREATE_DATE` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP , \n `UPDATE_DATE` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, \n SHARD KEY (`MODULE_ID`) \n ); \n INSERT INTO `BP_MODULE` \n (`MODULE_ID`, \n `MODULE_DESC`, \n `CREATED_BY`, \n `UPDATE_BY`, \n `CREATE_DATE`, \n `UPDATE_DATE`) \n VALUES \n (1, \n 'MUD', \n 1, \n 1, \n null, \n null);",
      "Comments": "https://dev.mysql.com/doc/refman/8.0/en/sql-mode.html",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Not enough memory available to complete the current request.",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6183",
      "Ticket Number": "#6183",
      "Title": "EOG - Prod - Leaf Error (houmsql15:3306): Not enough memory available to complete the current request. The request was not processed",
      "EOG cluster": "houmsql",
      "Host": "houmsql15:3306",
      "Solution": "To resolve the issue, recreate the table with a new shard key that evenly distributes data. You might consider adding another column to this index, to ensure the data is split up more evenly. \n Shard key testing/checking? memsql> SELECT DISTINCT(COUNT(*)) from production_actual group by entity_event_id, division_id;\n Test different sharding keys on production_actual that would more evenly distribute data. If no combination of columns in the shard key evenly distributes data, consider employing an auto_increment column.\n Recreate the table with the new sharding key and import the data.\n Temporarily stop the workload\n Drop the old table.\n Alter the new table to rename it with the old name.\n Start the workload again.",
      "Commands": "SELECT\n  DATABASE_NAME,\n  TABLE_NAME,\n  FLOOR(AVG(ROWS)) AS avg_rows,\n  ROUND(STDDEV(ROWS)/AVG(ROWS),3) * 100 AS row_skew,\n  FLOOR(AVG(MEMORY_USE)) AS avg_memory,\n  ROUND(STDDEV(MEMORY_USE)/AVG(MEMORY_USE),3) * 100 AS memory_skew\n FROM INFORMATION_SCHEMA.TABLE_STATISTICS\n GROUP BY 1, 2\n HAVING SUM(ROWS) > 10000\n ORDER BY row_skew DESC;",
      "RCA": "data skew detected on one node\n Any large tables indicating skew over 10% should be recreated with a more balanced shard key.\n (1) output of SHOW CLUSTER STATUS from the master aggregator\n (2) output of SHOW PARTITIONS on ie_dba from the master aggregator \n (3) A new cluster report (memsql-ops report)\n RC not detected but \" It looks like this cluster (houmsql) is replicating from another MemSQL cluster (ktymsql).\"\n \n We recommend recreating the table with a different shard key on the table production_actual because the partition 37 is using about 7 times more memory than any other partition. \n Please be sure to adjust the shard key on the primary cluster ktymsql.\n If there are no other columns that you could add to the shard key to evenly distribute data, then you might consider adding an auto_increment column to the table and adding it to the shard key instead.",
      "Comments": "https://docs.memsql.com/concepts/v6.0/data-skew/ https://docs.memsql.com/sql-reference/v6.0/create-table/#auto-increment-behavior https://docs.memsql.com/tutorials/v6.0/optimizing-table-data-structures/#choosing-a-shard-key",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Unable to ATTACH leaf",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6218",
      "Ticket Number": "#6218",
      "Title": "had to take a server offline",
      "EOG cluster": "ktymsqlfin11",
      "Host": "ktymsqlfin16':3307",
      "Solution": "You will need to make sure your leaf node comes fully online before running ATTACH LEAF.\n Successed.",
      "Commands": "memsql> ATTACH LEAF 'ktymsqlfin16':3307 NO REBALANCE;",
      "RCA": "n/a",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Upgrade assistance request for replication server",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6136",
      "Ticket Number": "#6136",
      "Title": "read-only replication server upgrade",
      "EOG cluster": "",
      "Host": "",
      "Solution": "successful upgrade based on docs",
      "Commands": "memsql> EXPLAIN RESTORE REDUNDANCY on cluster; \n memsql> EXPLAIN REBALANCE PARTITIONS on cluster;",
      "RCA": "status looks good only two warnings:\n All aggregators have max_connection_threads=1024\n \n recommended: 192\n concerns: if set too high the aggregator can consume too much of system resources like CPU\n All nodes have vm.swappiness = 1\n \n recommended: 10\n concerns: If set too low the system is less likely to swap memory when it is necessary, even though 16383 MB are allocated for swap on each host.",
      "Comments": "There are no extra steps necessary when upgrading a cluster that uses cluster replication as opposed to upgrading a normal cluster. It is not necessary to stop the replication. The secondary cluster will catch up on replication once it is upgraded and comes back up.\n If you would like you could consider pausing replication from the secondary cluster before upgrading. Then you can continue replicating it again once it is finished upgrading. However this is not necessary.\n Please do not stop replication. It is not possible to continue replication after stopping it, only after pausing it. If it is stopped entirely then to restart it again the database must be dropped again and start replicating from scratch. This can be very time consuming and resource intensive.\n https://docs.memsql.com/sql-reference/v6.0/stop-replicating/\n https://docs.memsql.com/sql-reference/v6.0/continue-replicating/\n https://docs.memsql.com/sql-reference/v6.0/pause-replicating/\n https://docs.memsql.com/operational-manual/v6.0/upgrading-to-latest-patch-version/\n memsql> EXPLAIN RESTORE REDUNDANCY;\n ERROR 1046 (3D000): No database selected\n \n memsql> EXPLAIN REBALANCE PARTITIONS;\n ERROR 1046 (3D000): No database selected\n For example:\n \n memsql> EXPLAIN RESTORE REDUNDANCY on database_name;\n These 2 commands are to check whether there are any necessary actions for restoring redundancy or rebalancing partitions.\n https://docs.memsql.com/tutorials/v6.0/installation-best-practices/\n  afetr upgrade two of this should be set\n 2 settings identified before that do not follow our recommended configuration settings\n all aggregators: max_connection_threads=1024\n recommended: 192\n all hosts: vm.swappiness = 1\n recommended: 10",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "trying to upgrade 6.5",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6375",
      "Ticket Number": "#6375",
      "Title": "trying to upgrade 6.5",
      "EOG cluster": "",
      "Host": "",
      "Solution": "DB replication finsihed.",
      "Commands": "",
      "RCA": "DB replication prevented the upgrade",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Dev memory error",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6333",
      "Ticket Number": "#6333",
      "Title": "EOG-Dev memory error",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Reduce memory usage by sharding tables differently.",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "[Houston C1] ktymsqlfin11 ******* One or more MemSQL nodes running out of Memory ************* (MySQL v2) Threshold not reached (Affected Rows) (0 #) (Ok)",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6524",
      "Ticket Number": "#6524",
      "Title": "[Houston C1] ktymsqlfin11 ******* One or more MemSQL nodes running out of Memory ************* (MySQL v2) Threshold not reached (Affected Rows) (0 #) (Ok)",
      "EOG cluster": "",
      "Host": "",
      "Solution": "ticket closed without action",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "EOG - Production redundancy validation - KTYMSQLFIN11",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6193",
      "Ticket Number": "#6193",
      "Title": "EOG - Production redundancy validation - KTYMSQLFIN11",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Validate the cluster",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "EOG - Error reading from socket warnings when dropping database ie_dba",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6179",
      "Ticket Number": "#6179",
      "Title": "EOG - Error reading from socket warnings when dropping database ie_dba",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Ignore the warnings",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Unable to connect to leaf @ktymsql26:3307",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6884",
      "Ticket Number": "#6884",
      "Title": "Memsql error - (1735, Leaf Error (ktymsql25:3308): Unable to connect to leaf @ktymsql26:3307 with user distributed, using password YES: [2005] Timed o",
      "EOG cluster": "ktymsql25",
      "Host": 3306,
      "Solution": "It is my understanding Phani was able to modify the workload to avoid hitting the timeout on leaf ktymsql26:3307.",
      "Commands": "",
      "RCA": "The proximate root cause is likely a transient spike in workload which causes the affected leaf to become too busy to accept the connection within 30 seconds. It's not clear what that workload was which caused this error.",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Slow prod cluster",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6903",
      "Ticket Number": "#6903",
      "Title": "EOG PROD  : Production performance degradation",
      "EOG cluster": "ktymsql30",
      "Host": "",
      "Solution": "Additionally the other 3 tables have more than 10% skew, and many rows. In particular ie_dba.ie_production_stitched has the highest skew at 11.1% and the greatest rows, over 12 million. I would recommend re-evaluating the sharding technique of this table and recreating it with a more even shard key.",
      "Commands": "SELECT\n    DATABASE_NAME,\n    TABLE_NAME,\n    FLOOR(AVG(ROWS)) AS avg_rows,\n    ROUND(STDDEV(ROWS)/AVG(ROWS),3) * 100 AS row_skew,\n    FLOOR(AVG(MEMORY_USE)) AS avg_memory,\n    ROUND(STDDEV(MEMORY_USE)/AVG(MEMORY_USE),3) * 100 AS memory_skew\nFROM INFORMATION_SCHEMA.TABLE_STATISTICS\nGROUP BY 1, 2\nHAVING SUM(ROWS) > 10000\nORDER BY row_skew DESC;",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "UNKILLABLE querries",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6899",
      "Ticket Number": "#6899",
      "Title": "EOG - Unkillable DROP commands while long running query present in cluster",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "Restart megoldottta",
      "Commands": "$ memsql -uroot -pPASSWORD -e \"_bt\" > backtrace.txt\nKILL CONNECTION 726927",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Backup + recovery",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6810",
      "Ticket Number": "#6810",
      "Title": "Prod - Backups and Recovery",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "Nem volt jó a permission, de utána átírták és már meg tudta csinálni a recomant",
      "Commands": "recoman -h",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Issue with Arrays in Stored Procedure",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6927",
      "Ticket Number": "#6927",
      "Title": "Re: Issue with Arrays in Stored Procedure",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "",
      "Commands": "This is a follow-up to your previous request #6925 \"Issue with Arrays in Stored Procedure",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "memory low",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6522",
      "Ticket Number": "#6522",
      "Title": "PRD-KTYMSQLFIN11 memory low warnings",
      "EOG cluster": "ktymsqlfin11",
      "Host": 3306,
      "Solution": "Commandok megoldották",
      "Commands": "$ memsql-ops memsql-update-config --key maximum_memory --value 346884 --set-global master_aggregator_memsql_id\n$ memsql-ops memsql-update-config --key maximum_memory --value 173442 --set-global child_aggregator_3306_memsql_id\n$ memsql-ops memsql-update-config --key maximum_memory --value 173442 --set-global child_aggregator_3307_memsql_id",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "not enough memory for request",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6507",
      "Ticket Number": "#6507",
      "Title": "Not Enough memory to Complete a request when using Thumbnails in a Columnstore Table",
      "EOG cluster": "ktymsqlfin16",
      "Host": 3307,
      "Solution": "n/a",
      "Commands": "n/a",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "long running queries",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6424",
      "Ticket Number": "#6424",
      "Title": "query running slow",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "We noticed that there is a potential mismatch between estimated table rows and actual rows on ie_dba.production_stitched",
      "Commands": "PROFILE select_statement; SHOW PROFILE",
      "RCA": "ColumnStoreScan ie_dba.production_stitched AS data, KEY default (date_value, entity_event_id) USING CLUSTERED COLUMNSTORE est_table_rows:1,747,180,841 est_filtered:1 actual_rows: 229,652,758 exec_time: 1,564ms start_time: [00:00:00.364, 00:00:00.415] memory_usage: 41,287.679688 KB segments_scanned: 2,401 segments_skipped: 16,683 segments_fully_contained: 0 |",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Auto Increment not working after upgrade",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6384",
      "Ticket Number": "#6384",
      "Title": "auto_increment field issue",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Agent upgrade failed",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6354",
      "Ticket Number": "#6354",
      "Title": "STG - agent upgrade failed with below",
      "EOG cluster": "houmsqlfin11",
      "Host": "n/a",
      "Solution": "Please be sure that this variable workload_management_memory_queuing is not set in the memsql.cnf file for either of the aggregators. If it is, it could prevent startup.",
      "Commands": "memsql-ops _upgrade --version 6.5.8\nmemsql-ops memsql-list -r master aggregator -q | xargs -n1 memsql-ops memsql-update-config --set-global --key leaf_pushdown_default --value off",
      "RCA": "agents were offline during the upgrade\nIt looks like `leaf_pushdown_default` is currently set to `ON` which is the cause of this problem. Please run the following",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "memsql upgrade from 6.0.20 to 6.0.23 - KTYMSQL30",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6075",
      "Ticket Number": "#6075",
      "Title": "memsql upgrade from 6.0.20 to 6.0.23 - KTYMSQL30",
      "EOG cluster": "KTYMSQL30",
      "Host": "",
      "Solution": "MEMSQL helped in the upgrade",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Leaf Error (houmsql15:3309): Leaf Error (houmsql15:3307): Leaf Error (houmsql29:3307): Can't open file: 'columns/ie_dba_91/1/4391451/368877564' (errno",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5949",
      "Ticket Number": "#5949",
      "Title": "Leaf Error (houmsql15:3309): Leaf Error (houmsql15:3307): Leaf Error (houmsql29:3307): Can't open file: 'columns/ie_dba_91/1/4391451/368877564' (errno",
      "EOG cluster": "",
      "Host": "houmsql15:3309 houmsql15:3307 houmsql29:3307",
      "Solution": "Replication finished",
      "Commands": "",
      "RCA": "Replication finished",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "stored procedure fails on some 6.0.23 clusters but not others?",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6010",
      "Ticket Number": "#6010",
      "Title": "stored procedure fails on some 6.0.23 clusters but not others?",
      "EOG cluster": "",
      "Host": "",
      "Solution": "ticket closed without action",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "EOG - Not enough memory available to complete the current request when running INSERT SELECT query",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5894",
      "Ticket Number": "#5894",
      "Title": "EOG - Not enough memory available to complete the current request when running INSERT SELECT query",
      "EOG cluster": "",
      "Host": "ktymsql27:3308",
      "Solution": "There was a huge table with bad shards",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "EOG - Testing Env - unrecoverable slave partitions, cannot truncate table",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5840",
      "Ticket Number": "#5840",
      "Title": "EOG - Testing Env - unrecoverable slave partitions, cannot truncate table",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Issue is fixed in 6.0.23",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Database unrecoverable",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5989",
      "Ticket Number": "#5989",
      "Title": "EOG - Dev Env - Database ODM_DBA unrecoverable caused by bug in 6.0.20",
      "EOG cluster": "ktymsqlstg41",
      "Host": "",
      "Solution": "memsql-ops memsql-upgrade  --version 6.0.24 --skip-snapshot --skip-version-check --no-backup-data-directories",
      "Commands": "",
      "RCA": "Please perform the following actions:\n\n(1) start the cluster\n\n(2) Create a connection into the MemSQL Master Aggregator\n\n(3) run DROP DATABASE ODM_DBA;\n\n(4) Collect output of EXPLAIN CLEAR ORPHAN DATABASES and send to us on this ticket\n\n(5) Upgrade the cluster to 6.0.23\n\n(6) Restore database ODM_DBA from backup",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "n/a",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6212",
      "Ticket Number": "#6212",
      "Title": "ktyvlxmsqliot",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "n/a",
      "RCA": "n/a",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Server nodes down",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5396",
      "Ticket Number": "#5396",
      "Title": "Server nodes went down.",
      "EOG cluster": "ktymsqlfin11",
      "Host": "",
      "Solution": "",
      "Commands": "This query caused the crash\n\n``` \ninsert into DP_CHECK \nselect c.chknbr, c.bnacct, c.cbcode, \ncase c.cbcode when ^ then ^ \nwhen ^ then ^ \nwhen ^ then ^ \nwhen ^ then ^ \nwhen ^ then ^ end check_status_desc,\n\n(select dt.date_id from DP_DATE dt where date_format(c.cbdate, '%Y-%m-%d') = dt.date_value) \nfrom APCBAPF c \n```\n\nThe subselect in this case is the `select dt.date_id from DP_DATE dt where date_format(c.cbdate, '%Y-%m-%d') = dt.date_value`.",
      "RCA": "Memsql upgrade megoldja a bugot",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "deadlock during replicating databases",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6026",
      "Ticket Number": "#6026",
      "Title": "EOG - deadlocks encountered during STOP REPLICATING and REPLICATE DATABASE",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "stop replication for iot_dba \nstop replication for iot_dba2\ndrop both databases and create new database oit_dba for replication again",
      "RCA": "drop databases hangingkelt, killelni kellett\nDo not run STOP REPLICATING + REPLICATE DATABASE of two different databases at the same time, this can also cause a deadlock (tracking with bug DB-32684)",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "EOG - misconfigured columnstore_segment_rows and vm.max_map_count in 6.0.20 cluster",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6034",
      "Ticket Number": "#6034",
      "Title": "EOG - misconfigured columnstore_segment_rows and vm.max_map_count in 6.0.20 cluster",
      "EOG cluster": "",
      "Host": "",
      "Solution": "",
      "Commands": "",
      "RCA": "Changeing the collumnstore segment rows +vm.max_map_count beállítása",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "EOG - CREATE DATABASE hanging on 6.0.13",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5404",
      "Ticket Number": "#5404",
      "Title": "EOG - CREATE DATABASE hanging on 6.0.13",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Fixed in 6.0.14",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "EOG - Cluster DB fails to recover on three leaf nodes",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5029",
      "Ticket Number": "#5029",
      "Title": "EOG - Cluster DB fails to recover on three leaf nodes",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Set numa up properly",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "EOG - ERROR on DR Slave Cluster: Partition's table metadata are out of sync for table",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/4948",
      "Ticket Number": "#4948",
      "Title": "EOG - ERROR on DR Slave Cluster: Partition's table metadata are out of sync for table",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Fixed in 6.0.0",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Leaf going down",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/4761",
      "Ticket Number": "#4761",
      "Title": "Leaf going down",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Root cause not found, no solution was given",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "EOG - Three (3) misconfigurations in production MemSQL Cluster",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/4654",
      "Ticket Number": "#4654",
      "Title": "EOG - Three (3) misconfigurations in production MemSQL Cluster",
      "EOG cluster": "",
      "Host": "",
      "Solution": "Set numa up properly",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Error Code: 1889. Bad distributed join plan: leaf select contains sharded tables of multiple databases.",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5637",
      "Ticket Number": "#5637",
      "Title": "Error on UNION Statement",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "n/a",
      "RCA": "Querry Processing team kezelte",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Difference between reference and rowstore",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5527",
      "Ticket Number": "#5527",
      "Title": "Query Update Errors",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "Reference tables are handled differently than standard tables. For example they are expected to be much smaller, and rather than being sharded across the leaves, they are replicated to all nodes, including aggregators. This means all nodes have a local copy to work with, rather than performing distributed operations when running a JOIN or other operation.",
      "RCA": "n/a",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "1162 Function `ie_update_scenario_member_sp` has been compiled without optimizations because it is too large. 0.453 sec",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5421",
      "Ticket Number": "#5421",
      "Title": "Critical error in stored procedures",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "There is no maximum length of Procedural SQL functions. The error you are seeing occurs when a Procedural SQL function exceeds the default of 50 statements (this value is modifiable with the optimize_stmt_threshold session variable)",
      "RCA": "Új updateben elvileg már megoldótott",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Permission issue",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5436",
      "Ticket Number": "#5436",
      "Title": "EOG - hitting permission issue when using Ops database-backup",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "n/a",
      "RCA": "The following happens when you run a backup using memsql-ops database-backup",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Trying to replicate 5.8 database to 6.0, getting the following error",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5382",
      "Ticket Number": "#5382",
      "Title": "EOG - Cannot replicate from V5 to V6",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "backup and restore",
      "Commands": "Replicating a 5.8 database to a 6.0 database is not supported.",
      "RCA": "RROR 1218 (08S01): Error connecting to master: master is running an incompatible version of MemSQL",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "buffer manager memory allocation failure",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6135",
      "Ticket Number": "#6135",
      "Title": "EOG - Memory exceptions in production cluster",
      "EOG cluster": "houmsql",
      "Host": "houmsql15/30:3306",
      "Solution": "suggested: periodically run ANALYZE on all tables, particularly those with columns on which range statistics have been enabled.\n recommend periodically running analyze on tables that use automatic statistics, though it is not necessary to run as frequently as on those without autostats.",
      "Commands": "memsql -h HOST -u USER -pPASSWORD -e \"SHOW PROFILE\"> profile.txt\n SHOW PROFILE; while script is running, in order to possible kill query - after 2-hour run - check it with this:\n SHOW PROCESSLIST\n SHOW PROFILE PROCESS process_id\n ANALYZE TABLE table_name; for all query-included tables and their PROFILE <SELECT ...>; \n Analysis will collect performancetuning related info\n SHOW PROFILE; \n then also recollect show profile with kill\n bash script for analyse tables:\n \"#!/usr/bin/env bash \n set -euo pipefail \n DATABASE='' \n host='127.1' \n user='root' \n port='3306' \n mysql_cmd=\"mysql --raw -h$host -u$user -P$port\" \n function query() \n { \n if [[ -n \"$DATABASE\" ]]; then \n $mysql_cmd -D \"$DATABASE\" -e \"$1\" | tail -n+2 \n else \n $mysql_cmd -e \"$1\" | tail -n+2 \n fi \n } \n mysqldump -P\"$port\" -h\"$host\" -u\"$user\" --skip-opt --all-databases --no-data --lock-tables=false --compact > import.sql \n for db in $(query \"show databases\"); do \n if [[ $db = memsql || $db = cluster || $db = information_schema ]]; then \n continue \n fi \n DATABASE=\"$db\" \n for table in $(query \"show tables\"); do \n query \"ANALYZE TABLE \\`$table\\`\" || true \n query \"ANALYZE TABLE \\`$table\\` INTO OUTFILE '/tmp/analyze_dump_${db}_${table}.json'\" || true \n query \"SHOW CREATE TABLE $table\" > schema_dump_${db}_${table}.sql \n echo \"ANALYZE TABLE \\`$db\\`.\\`$table\\` INFILE '/tmp/analyze_dump_${db}_${table}.json';\" >> import.sql \n done \n done \n query \"analyze optimizer_state into outfile '/tmp/analyze_optimizer_state.json'\" \n echo \"ANALYZE OPTIMIZER_STATE INFILE '/tmp/analyze_optimizer_state.json';\" >> import.sql \n ```\"\n SHOW DATABASES EXTENDED was error msg-ed while collection info from replicating db\n AUTOSTATS_ENABLED=TRUE needst o set before memsql v6 \n for range statistics check like histograms enabled run this: memsql> select DATABASE_NAME, TABLE_NAME, COLUMN_NAME from INFORMATION_SCHEMA.RANGE_STATISTICS group by DATABASE_NAME, TABLE_NAME, COLUMN_NAME;",
      "RCA": "5111736657245 2018-07-02 13:41:53.305 ERROR: Nonfatal buffer manager memory allocation failure. Memory use (106296.000000 MB) has reached the maximum_memory parameter (106496 MB).\n This msg was logged , after 1-hour this issue was gone parallel with memousage decrease\n explain and profile of sql-s was asked with report\n Though column statistics (counts of distinct values per column, count of NULLs per column, row count per table, etc) are automatically collected on columnstore tables, histograms are a type of range statistic which must be manually enabled and manually periodically collected by running ANALYZE on the table.\n It might be quereid tables were not set to statistics on status to optimization",
      "Comments": "Please note that stopping the query will stop the profiling of it before it finishes. This may make it unusable.\n Explain will not run the query only profile",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Grant error to not-existing user",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/6063",
      "Ticket Number": "#6063",
      "Title": "Memsql grants to a non existing user does not generate any Error",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "n/a",
      "Commands": "n/a",
      "RCA": "n/a",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "MemSQL upgrade",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5644",
      "Ticket Number": "#5644",
      "Title": "Upgrade MemSQL 5.8 to latest 6.0 release (6.0.20)",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "",
      "Commands": "upgrade needs to have not unomitored dbs, check with this on MASTER aggregator:\n memsql-ops memsql-list --include-unmonitored\n if there are listed ones remove them\n for cluster and partition state checking:\n SHOW LEAVES;\n SHOW AGGREGATORS;\n SHOW CLUSTER STATUS;\n EXPLAIN RESTORE REDUNDANCY on database_name;\n EXPLAIN REBALANCE PARTITIONS on database_name;\n upgrading in this scenario, you should follow:\n \n Stop the workload.\n Upgrade OPS on the secondary (read-only) cluster.\n Upgrade the secondary (read-only) cluster.\n Upgrade OPS on the primary (read/write) cluster.\n Upgrade the primary (read/write) cluster.\n Drop any replicated databases from the secondary cluster DROP DATABASE database_name\n Start replication again on the secondary cluster REPLICATE DATABASE db_name FROM master_user[:'master_password']@master_host[:master_port][/master_db_name]\n Start the workload.",
      "RCA": "check pre-upgrade steps\n reports statuses seemed ingood condition only NUMA was not configurad",
      "Comments": "https://docs.memsql.com/operational-manual/v6.0/upgrading-to-60/#step-1-verify-your-cluster-is-ready-for-upgrade",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "MemSQL upgrade error handling",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5747",
      "Ticket Number": "#5747",
      "Title": "Error in upgrade",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "During the call we observed most agents reporting as OFFLINE. I believe this was due to the primary agent having a hiccup or timeout when it was its turn to be upgraded. The fact that the primary was on 5.8.2 and all followers were on 6.0.10 lead to them reporting as OFFLINE.\n \n We went into the primary agent node and ran memsql-ops _upgrade -v 6.0.10 to manually upgrade this node, which upgraded successfully. Once the primary agent was on 6.0.10, the rest of the agents reported as ONLINE and using 6.0.10.",
      "Commands": "memsql-ops memsql-list --include-unmonitored\n memsql-ops agent-list\n ps ef | grep memsql",
      "RCA": "memsql-ops memsql-list --include-unmonitored listed two false monitored leaf shoudl remove before upgrade",
      "Comments": "Note that upgrading to MemSQL Ops version 6 will leave MemSQL Ops unable to fully manage your cluster until MemSQL is also upgraded to version 6.\n https://docs.memsql.com/memsql-ops-cli-reference/v5.8/agent-uninstall/\n https://docs.memsql.com/memsql-ops-cli-reference/v6.0/agent-start/",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "sync users between the cluster",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5730",
      "Ticket Number": "#5730",
      "Title": "How to sync users between the clusters",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "users need to be added to new nodes, no automatic grant",
      "Commands": "SHOW GRANTS FOR user@domain;\n memsql> SHOW GRANTS;\n GRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' WITH GRANT OPTION",
      "RCA": "",
      "Comments": "Passwords are associated to users. Since passwords are node-specific, their associated passwords are also node-specific.\n However syncing users across the cluster is something that we are currently developing! \n bash script for user grants export into sql:\n #!/bin/bash\n #./user_backup.sh -o <outputfile with sql> -h memsql_host -u user -p password -o /path/to/dsqlfile\n \n #defaults\n outfile=\"grants-$(date +%F_%H_%M).sql\"\n host=\"127.0.01\"\n user=\"root\"\n port=\"3306\"\n \n while getopts \":o:h:u:p:P:\" opt; do\n  case $opt in\n  o) outfile=$OPTARG\n  ;;\n  h) host=$OPTARG\n  ;;\n  u) user=$OPTARG\n  ;;\n  p) pass=$OPTARG\n  ;;\n  P) port=$OPTARG\n  ;;\n  esac\n done\n \n echo \"Backing up grants from $host to the file $outfile\"\n \n \n if [ -z \"$pass\" ]; then \n  mysql_command=\"mysql -h$host -u$user -P$port \"\n else \n  mysql_command=\"mysql -h$host -u$user -P$port -p$pass\"\n fi\n \n echo \"Connection string is: $mysql_command\"\n cmd=\"for i in \\`$mysql_command -e 'select distinct grantee from information_schema.user_privileges;' | awk {'print \\$1'}| grep -v 'grantee'\\`; do $mysql_command -e \"'\"'\"show grants for \\$i\"'\"'\" >> $outfile; done\"\n \n eval $cmd\n sed -i '/Grants for.*/d' \"$outfile\"\n sed -i 's/$/;/' \"$outfile",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Grant grant permission",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/5665",
      "Ticket Number": "#5665",
      "Title": "grants by role and group",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "right command use solved: GRANT ALL ON landdm.* TO ROLE 'LAND_DBA' WITH GRANT OPTION;",
      "Commands": "grant execute on WriteActionLog to 'landdm_con'@'%'; this was not executed for specific user\n for checking roles/groups for user:\n show grants for 'land_dba'@'%';\n SHOW GROUPS FOR USER 'land_dba'@'%';\n SHOW GROUPS FOR ROLE 'LAND_DBA';\n GRANT ALL ON landdm.* TO ROLE 'LAND_DBA'@'%' IDENTIFIED BY 'testpass123' WITH GRANT OPTION; \n GRANT GRANT OPTION on *.* to ROLE 'compliance_role';\n GRANT GRANT OPTION on *.* to 'user_specification';\n Roles do not have a host specification nor password, so correct command:\n GRANT ALL ON landdm.* TO ROLE 'LAND_DBA' WITH GRANT OPTION;\n DROP USER 'LAND_DBA'@'%'",
      "RCA": "The GRANT privilege allows user A to grant user B privileges that user A does not have.\n Please note that in MemSQL WITH GRANT OPTION will allow user A to grant user B any privileges that user A has.",
      "Comments": "Please note that users, groups, and roles are per node. If you would like to be able to connect to all nodes/aggregators as the user xyz then it is necessary to configure it on all nodes/aggregators.\n Please be sure to grant the GRANT permission to the role xyz. This is different from with grant option.\n https://docs.memsql.com/sql-reference/v6.0/permissions-matrix/",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Child aggregator deploy",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/4808",
      "Ticket Number": "#4808",
      "Title": "add an aggregator to ktymsqlfin12 at port 3307",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "memsql-ops memsql-deploy -a A9b6483(other single aggregator ID) -r aggregator -P 3307\n then root and other users permission set",
      "Commands": "memsql-ops memsql-deploy -a A9b6483(other single aggregator ID) -r aggregator -P 3307",
      "RCA": "",
      "Comments": "https://docs.memsql.com/memsql-ops-cli-reference/v6.0/memsql-deploy/\n https://docs.memsql.com/memsql-ops-cli-reference/v6.0/memsql-update-root-password/\n when a new node is deployed, it is deployed with blank permissions",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Leaf node removal",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/4793",
      "Ticket Number": "#4793",
      "Title": "Memsql Leaf node removal",
      "EOG cluster": "houmsqlfin11",
      "Host": "n/a",
      "Solution": "REMOVE LEAF 'host':port [FORCE] with\n memsql-ops agent-uninstall --agent-id A045d10 --force",
      "Commands": "memsql-ops memsql-list, memsql-ops agent-list, connecting to the database and running SHOW CLUSTER STATUS and SHOW LEAVES.\n REMOVE LEAF 'host':port [FORCE]\n memsql-ops agent-uninstall --agent-id A045d10 --force",
      "RCA": "",
      "Comments": "https://docs.memsql.com/sql-reference/v6.0/remove-leaf/ https://docs.memsql.com/memsql-ops-cli-reference/v6.0/memsql-unmonitor/ https://docs.memsql.com/memsql-ops-cli-reference/v6.0/agent-uninstall/",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Replication issue",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/4745",
      "Ticket Number": "#4745",
      "Title": "Replication issue",
      "EOG cluster": "ktymsql30",
      "Host": "n/a",
      "Solution": "solved by user later with original commands",
      "Commands": "n/a",
      "RCA": "first worked for user :\n drop database \n REPLICATE DATABASE name FROM root:'password'@hostname:3306 \n stop replication database.\n Later confirmed above worked again, show replication status message was printed after error where an async slave node replicating status was showed",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "DETACH LEAF hanging",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/4661",
      "Ticket Number": "#4661",
      "Title": "EOG - DETACH LEAF hanging",
      "EOG cluster": "n/a",
      "Host": "houmsql29':3306",
      "Solution": "queued processes needed to kill that prevented detaching\n other processes shoudl be stopped as well but this is difficult to do so master aggregator restart helped",
      "Commands": "1) snapshot databases \n 2) enable manual control \n 3) memsql>SET GLOBAL auto_attach=OFF; \n memsql>SET GLOBAL aggregator_failure_detection=OFF; \n memsql>SET GLOBAL leaf_failure_detection=OFF;\n 4) DETACH LEAF 'houmsql29':3306; -----------------> STUCK\n memsql-ops report;\n ps aux | grep memsqld to find the pid associated with the master agg parent process\n sudo kill -9 master_agg_parent_pid\n Ops should automatically restart the master aggregator. If you have manual control enabled in Ops then Ops will not automatically start the Master Agg following the kill -9. If ops does not automatically start the master agg you can do so using memsql-ops memsql-stop master_agg_ID and memsql-ops memsql-start master_agg_ID.\n after detecting more ingestion jobs:\n pause your ingestion workload\n ps aux | grep memsqld to find the pid associated with the master agg parent process\n sudo kill -9 master_agg_parent_pid\n Ops should automatically restart the master aggregator. If you have manual control enabled in Ops then Ops will not automatically start the Master Agg following the kill -9. If ops does not automatically start the master agg you can do so using memsql-ops memsql-stop master_agg_ID and memsql-ops memsql-start master_agg_ID.\n You will need to run the detach leaf command again when the master aggregator comes back online.\n Resume your ingestion workload",
      "RCA": "Following directions to shutdown a node to add memory,\n High Availability and workload seetings info was asked with report\n long running delete was extracted from report - two option suggested in this case: wait or a bloody kill\n from report a 2-hour long delete process was also listet, for this performance check was recommended",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "Production Outage",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/4648",
      "Ticket Number": "#4648",
      "Title": "EOG - Unable to create database tables, Production Outage",
      "EOG cluster": "n/a",
      "Host": "n/a",
      "Solution": "not provided only root cause analyis was communicated, further info provide not happened",
      "Commands": "memsql bare-metal",
      "RCA": "cluster report and c.report after prod outage was asked for root cause analysis:\n It looks like the way the cluster was restarted induced failover between leaf nodes unintentionally. While your master aggregator was online leaf nodes were shut down which induces failover. In this scenario the master aggregator should be turned off prior to shutting down leaves. The command memsql-ops memsql-stop --all will first shut down the master aggregator then shut down leaf nodes. It's possible your master aggregator was in an inconsistent state which prevented it from being shut down normally.\n There were orphan dbs during restart , they caused also failover\n The orphan partitions are the result of the master aggregator shutting off while in the middle of failover. The master aggregator was unsure what to do with the partitions so it placed them into orphan status and relies on the DBA to determine what should be done with the Orphan partitions:",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    },
    {
      "Short Desc.": "DB replicating issue",
      "Ticket Link": "https://support.memsql.com/hc/en-us/requests/4223",
      "Ticket Number": "#4223",
      "Title": "DB replicating issue",
      "EOG cluster": "",
      "Host": "",
      "Solution": "There was no issue.",
      "Commands": "",
      "RCA": "",
      "Comments": "",
      "EOG_Ticket#": "",
      "": "",
      "__1": "",
      "__2": "",
      "__3": "",
      "__4": "",
      "__5": "",
      "__6": "",
      "__7": "",
      "__8": "",
      "__9": "",
      "__10": "",
      "__11": "",
      "__12": "",
      "__13": "",
      "__14": "",
      "__15": "",
      "__16": ""
    }
  ]
};
